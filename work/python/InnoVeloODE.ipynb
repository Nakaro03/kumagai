{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995ac52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ogb in /home/nakamuraroi/.local/lib/python3.8/site-packages (1.3.6)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (1.3.2)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /usr/lib/python3/dist-packages (from ogb) (1.25.8)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from ogb) (1.14.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (2.4.1)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (0.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (1.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (4.13.2)\n",
      "Requirement already satisfied: filelock in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.16.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (2.20.5)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (9.1.0.70)\n",
      "Requirement already satisfied: fsspec in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n",
      "Requirement already satisfied: littleutils in /home/nakamuraroi/.local/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=44 in /usr/lib/python3/dist-packages (from outdated>=0.2.0->ogb) (45.2.0)\n",
      "Requirement already satisfied: requests in /home/nakamuraroi/.local/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (2.32.4)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.6.0->ogb) (12.9.86)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->outdated>=0.2.0->ogb) (2019.11.28)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->outdated>=0.2.0->ogb) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b26bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /home/nakamuraroi/.local/lib/python3.8/site-packages (2.6.1)\n",
      "Requirement already satisfied: fsspec in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (2024.9.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (7.1.3)\n",
      "Requirement already satisfied: jinja2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (1.24.4)\n",
      "Requirement already satisfied: pyparsing in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: tqdm in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (2.32.4)\n",
      "Requirement already satisfied: aiohttp in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (3.10.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2019.11.28)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from requests->torch_geometric) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2.8)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.15.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->torch_geometric) (19.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (2.4.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0; python_version < \"3.11\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0; python_version < \"3.11\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23a3d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データをロード中（パッチ適用済み）...\n",
      "--------------------------------\n",
      "【セットアップ完了】\n",
      "ノード数: 169343\n",
      "特徴量次元: 128\n",
      "これでNeural ODEの実装に進めます。\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import functools\n",
    "\n",
    "# --- 【緊急パッチ】PyTorch 2.6のセキュリティ制限を解除 ---\n",
    "_original_load = torch.load\n",
    "\n",
    "def unsafe_load(*args, **kwargs):\n",
    "    # 強制的にセキュリティチェックを無効化 (weights_only=False)\n",
    "    if 'weights_only' not in kwargs:\n",
    "        kwargs['weights_only'] = False\n",
    "    return _original_load(*args, **kwargs)\n",
    "\n",
    "torch.load = unsafe_load\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"データをロード中（パッチ適用済み）...\")\n",
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='./data')\n",
    "data = dataset[0]\n",
    "\n",
    "# パッチを戻す（念のため）\n",
    "torch.load = _original_load\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(\"【セットアップ完了】\")\n",
    "print(f\"ノード数: {data.num_nodes}\")\n",
    "print(f\"特徴量次元: {data.x.shape[1]}\")\n",
    "print(\"これでNeural ODEの実装に進めます。\")\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76420886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== データの全体像 ===\n",
      "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])\n",
      "\n",
      "=== 論文の特徴量（最初の5件） ===\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.057943 -0.052530 -0.072603 -0.026555  0.130435 -0.241386 -0.449242   \n",
      "1 -0.124500 -0.070665 -0.325202  0.007779 -0.001559  0.074189 -0.191013   \n",
      "2 -0.080242 -0.023328 -0.183787 -0.180707  0.075765 -0.125818 -0.394573   \n",
      "3 -0.145044  0.054915 -0.126666  0.039971 -0.055909 -0.101278 -0.339202   \n",
      "4 -0.071154  0.070766 -0.281432 -0.161892 -0.165246 -0.029116 -0.338593   \n",
      "\n",
      "        7         8         9    ...       118       119       120       121  \\\n",
      "0 -0.018443 -0.087218  0.112320  ...  0.211490 -0.226118 -0.185603  0.053230   \n",
      "1  0.049689  0.026369  0.099364  ...  0.106316  0.052926 -0.258378  0.021567   \n",
      "2 -0.219078 -0.108931  0.056966  ...  0.019453 -0.070291 -0.177562 -0.214012   \n",
      "3 -0.115801 -0.080058 -0.001633  ... -0.065752  0.042735  0.066338 -0.226921   \n",
      "4 -0.138727  0.100015  0.132794  ... -0.056130  0.047475 -0.263795  0.026462   \n",
      "\n",
      "        122       123       124       125       126       127  \n",
      "0  0.332873  0.104175  0.007408  0.173364 -0.172796 -0.140059  \n",
      "1  0.281503 -0.173423  0.202082  0.068524 -0.372111 -0.301036  \n",
      "2  0.182186 -0.121589 -0.073642  0.109919  0.117589 -0.139883  \n",
      "3  0.188418 -0.017295  0.063449  0.017816  0.085364 -0.081804  \n",
      "4  0.376349 -0.253772  0.084472  0.098033 -0.075347 -0.111687  \n",
      "\n",
      "[5 rows x 128 columns]\n",
      "\n",
      "=== 引用関係（最初の5リンク） ===\n",
      "          引用元ID   引用先ID\n",
      "0        104447   13091\n",
      "1         15858   47283\n",
      "2        107156   69161\n",
      "3        107156  136440\n",
      "4        107156  107366\n",
      "...         ...     ...\n",
      "1166238   45118   79124\n",
      "1166239   45118  147994\n",
      "1166240   45118  162473\n",
      "1166241   45118  162537\n",
      "1166242   45118   72717\n",
      "\n",
      "[1166243 rows x 2 columns]\n",
      "\n",
      "=== 出版年（最初の5件） ===\n",
      "tensor([2013, 2015, 2014, 2014, 2014])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. データ全体の要約を見る\n",
    "print(\"=== データの全体像 ===\")\n",
    "print(data) \n",
    "\n",
    "# 2. 特徴量（x）の中身を少しだけ見る\n",
    "print(\"\\n=== 論文の特徴量（最初の5件） ===\")\n",
    "# 128個の数字の並びが、1つの論文の意味を表しています\n",
    "df_x = pd.DataFrame(data.x[:5].numpy())\n",
    "print(df_x)\n",
    "\n",
    "# 3. 引用関係（edge_index）の中身を見る\n",
    "print(\"\\n=== 引用関係（最初の5リンク） ===\")\n",
    "# [引用元ID, 引用先ID] のペアです\n",
    "edges = data.edge_index.t()[:]\n",
    "df_edges = pd.DataFrame(edges.numpy(), columns=[\"引用元ID\", \"引用先ID\"])\n",
    "print(df_edges)\n",
    "\n",
    "# 4. 年データを見る\n",
    "print(\"\\n=== 出版年（最初の5件） ===\")\n",
    "print(data.node_year[:5].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f8310a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>引用元ID</th>\n",
       "      <th>引用先ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104447</td>\n",
       "      <td>13091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15858</td>\n",
       "      <td>47283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107156</td>\n",
       "      <td>69161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107156</td>\n",
       "      <td>136440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107156</td>\n",
       "      <td>107366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166238</th>\n",
       "      <td>45118</td>\n",
       "      <td>79124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166239</th>\n",
       "      <td>45118</td>\n",
       "      <td>147994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166240</th>\n",
       "      <td>45118</td>\n",
       "      <td>162473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166241</th>\n",
       "      <td>45118</td>\n",
       "      <td>162537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166242</th>\n",
       "      <td>45118</td>\n",
       "      <td>72717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          引用元ID   引用先ID\n",
       "0        104447   13091\n",
       "1         15858   47283\n",
       "2        107156   69161\n",
       "3        107156  136440\n",
       "4        107156  107366\n",
       "...         ...     ...\n",
       "1166238   45118   79124\n",
       "1166239   45118  147994\n",
       "1166240   45118  162473\n",
       "1166241   45118  162537\n",
       "1166242   45118   72717\n",
       "\n",
       "[1166243 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/nakamuraroi/.local/lib/python3.8/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/nakamuraroi/.local/lib/python3.8/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OGBN-Arxiv カテゴリ ID (0-39) 対照表 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Arxiv Category Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>arxiv cs na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arxiv cs mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arxiv cs lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>arxiv cs cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>arxiv cs cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arxiv cs dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>arxiv cs hc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>arxiv cs ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>arxiv cs ni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>arxiv cs cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>arxiv cs ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>arxiv cs ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>arxiv cs gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>arxiv cs ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>arxiv cs sc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>arxiv cs ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>arxiv cs cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>arxiv cs gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>arxiv cs et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>arxiv cs sy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>arxiv cs cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>arxiv cs oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>arxiv cs pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>arxiv cs se</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>arxiv cs lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>arxiv cs sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>arxiv cs si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>arxiv cs ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>arxiv cs it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>arxiv cs pf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>arxiv cs cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>arxiv cs ir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>arxiv cs ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>arxiv cs fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>arxiv cs ds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>arxiv cs os</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>arxiv cs gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>arxiv cs db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>arxiv cs dl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>arxiv cs dm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Arxiv Category Code\n",
       "0    0         arxiv cs na\n",
       "1    1         arxiv cs mm\n",
       "2    2         arxiv cs lo\n",
       "3    3         arxiv cs cy\n",
       "4    4         arxiv cs cr\n",
       "5    5         arxiv cs dc\n",
       "6    6         arxiv cs hc\n",
       "7    7         arxiv cs ce\n",
       "8    8         arxiv cs ni\n",
       "9    9         arxiv cs cc\n",
       "10  10         arxiv cs ai\n",
       "11  11         arxiv cs ma\n",
       "12  12         arxiv cs gl\n",
       "13  13         arxiv cs ne\n",
       "14  14         arxiv cs sc\n",
       "15  15         arxiv cs ar\n",
       "16  16         arxiv cs cv\n",
       "17  17         arxiv cs gr\n",
       "18  18         arxiv cs et\n",
       "19  19         arxiv cs sy\n",
       "20  20         arxiv cs cg\n",
       "21  21         arxiv cs oh\n",
       "22  22         arxiv cs pl\n",
       "23  23         arxiv cs se\n",
       "24  24         arxiv cs lg\n",
       "25  25         arxiv cs sd\n",
       "26  26         arxiv cs si\n",
       "27  27         arxiv cs ro\n",
       "28  28         arxiv cs it\n",
       "29  29         arxiv cs pf\n",
       "30  30         arxiv cs cl\n",
       "31  31         arxiv cs ir\n",
       "32  32         arxiv cs ms\n",
       "33  33         arxiv cs fl\n",
       "34  34         arxiv cs ds\n",
       "35  35         arxiv cs os\n",
       "36  36         arxiv cs gt\n",
       "37  37         arxiv cs db\n",
       "38  38         arxiv cs dl\n",
       "39  39         arxiv cs dm"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- OGBマッピングの動的ロード (再現用) ---\n",
    "# 実際のデータが読み込まれていることを確認します。\n",
    "root_dir = './data'\n",
    "mapping_path = os.path.join(root_dir, 'ogbn_arxiv/mapping/labelidx2arxivcategeory.csv.gz')\n",
    "\n",
    "try:\n",
    "    label_df = pd.read_csv(mapping_path)\n",
    "    # IDをキー、カテゴリコードを値とする辞書を作成\n",
    "    ARXIV_CATEGORY_NAMES = dict(zip(label_df['label idx'], label_df['arxiv category']))\n",
    "except Exception:\n",
    "    # 失敗した場合はダミーデータを使用（元のコードのロジックを再現）\n",
    "    ARXIV_CATEGORY_NAMES = {i: f'Dummy_Cat_{i}' for i in range(40)}\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "# IDとカテゴリコードのペアを抽出し、データフレームを作成\n",
    "category_data = []\n",
    "# 0から39までのIDを明示的に処理\n",
    "for cat_id in range(40):\n",
    "    category_code = ARXIV_CATEGORY_NAMES.get(cat_id, 'N/A')\n",
    "    category_data.append([cat_id, category_code])\n",
    "\n",
    "# DataFrameの作成\n",
    "df_categories = pd.DataFrame(category_data, columns=['ID', 'Arxiv Category Code'])\n",
    "\n",
    "print(\"=== OGBN-Arxiv カテゴリ ID (0-39) 対照表 ===\")\n",
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d02d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/nakamuraroi/.local/lib/python3.8/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/nakamuraroi/.local/lib/python3.8/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✓ Output directory created: visualizations_output\n",
      "\n",
      "✓ OGB-Arxiv Categories Loaded: 40 unique labels.\n",
      "\n",
      "====================================================================================================\n",
      "DYNAMIC GRAPH LEARNING WITH ADVANCED EVALUATION\n",
      "====================================================================================================\n",
      "\n",
      "STEP 1: Loading Data...\n",
      "Loading dataset: ogbn-arxiv...\n",
      "✓ Loaded OGB dataset successfully\n",
      "✓ Data loaded: 169343 papers, 40 categories.\n",
      "\n",
      "STEP 2: Building Dynamic Graphs...\n",
      "Building temporal snapshots...\n",
      "✓ Built 6 snapshots.\n",
      "✓ Time snapshots: [2015, 2016, 2017, 2018, 2019, 2020]\n",
      "✓ Categories: 40, Feature dim: 128\n",
      "\n",
      "STEP 3: Initializing Models (Baselines & Ablation)...\n",
      "✓ Using GAT (2 heads) - Mode: adaptive_decay\n",
      "✓ Using GAT (2 heads) - Mode: no_decay\n",
      "✓ Using GAT (2 heads) - Mode: no_velocity\n",
      "  ✓ Static GCN\n",
      "  ✓ GRAND (Diffusion)\n",
      "  ✓ GREAD (React-Diff)\n",
      "  ✓ InnoVelo (Full)\n",
      "  ✓ InnoVelo (No Decay)\n",
      "  ✓ InnoVelo (No Velocity)\n",
      "\n",
      "STEP 4: Training Models...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training Static GCN...\n",
      "Static GCN - Epoch 01/5 | Loss: 1.2685 | AUC: 0.7263\n",
      "Static GCN - Epoch 02/5 | Loss: 1.1167 | AUC: 0.8108\n",
      "Static GCN - Epoch 03/5 | Loss: 1.0410 | AUC: 0.8410\n",
      "Static GCN - Epoch 04/5 | Loss: 0.9818 | AUC: 0.8622\n",
      "Static GCN - Epoch 05/5 | Loss: 0.9419 | AUC: 0.8748\n",
      "\n",
      "Training GRAND (Diffusion)...\n",
      "GRAND (Diffusion) - Epoch 01/5 | Loss: 1.3763 | AUC: 0.5789\n",
      "GRAND (Diffusion) - Epoch 02/5 | Loss: 1.2834 | AUC: 0.7313\n",
      "GRAND (Diffusion) - Epoch 03/5 | Loss: 1.1017 | AUC: 0.8188\n",
      "GRAND (Diffusion) - Epoch 04/5 | Loss: 0.9020 | AUC: 0.8800\n",
      "GRAND (Diffusion) - Epoch 05/5 | Loss: 0.8651 | AUC: 0.8997\n",
      "\n",
      "Training GREAD (React-Diff)...\n",
      "GREAD (React-Diff) - Epoch 01/5 | Loss: 1.2490 | AUC: 0.7397\n",
      "GREAD (React-Diff) - Epoch 02/5 | Loss: 1.0265 | AUC: 0.8488\n",
      "GREAD (React-Diff) - Epoch 03/5 | Loss: 0.9471 | AUC: 0.8745\n",
      "GREAD (React-Diff) - Epoch 04/5 | Loss: 0.9230 | AUC: 0.8833\n",
      "GREAD (React-Diff) - Epoch 05/5 | Loss: 0.8586 | AUC: 0.8879\n",
      "\n",
      "Training InnoVelo (Full)...\n",
      "InnoVelo (Full) - Epoch 01/5 | Loss: 1.3635 | AUC: 0.6164\n",
      "InnoVelo (Full) - Epoch 02/5 | Loss: 1.2720 | AUC: 0.7315\n",
      "InnoVelo (Full) - Epoch 03/5 | Loss: 1.1467 | AUC: 0.7705\n",
      "InnoVelo (Full) - Epoch 04/5 | Loss: 1.1039 | AUC: 0.7898\n",
      "InnoVelo (Full) - Epoch 05/5 | Loss: 1.1105 | AUC: 0.7985\n",
      "\n",
      "Training InnoVelo (No Decay)...\n",
      "InnoVelo (No Decay) - Epoch 01/5 | Loss: 1.3541 | AUC: 0.6627\n",
      "InnoVelo (No Decay) - Epoch 02/5 | Loss: 1.2453 | AUC: 0.7557\n",
      "InnoVelo (No Decay) - Epoch 03/5 | Loss: 1.1984 | AUC: 0.7636\n",
      "InnoVelo (No Decay) - Epoch 04/5 | Loss: 1.2004 | AUC: 0.7782\n",
      "InnoVelo (No Decay) - Epoch 05/5 | Loss: 1.1519 | AUC: 0.7854\n",
      "\n",
      "Training InnoVelo (No Velocity)...\n",
      "InnoVelo (No Velocity) - Epoch 01/5 | Loss: 1.3600 | AUC: 0.6413\n",
      "InnoVelo (No Velocity) - Epoch 02/5 | Loss: 1.2555 | AUC: 0.7396\n",
      "InnoVelo (No Velocity) - Epoch 03/5 | Loss: 1.1078 | AUC: 0.8079\n",
      "InnoVelo (No Velocity) - Epoch 04/5 | Loss: 0.9561 | AUC: 0.8504\n",
      "InnoVelo (No Velocity) - Epoch 05/5 | Loss: 0.8835 | AUC: 0.8814\n",
      "\n",
      "STEP 5: Evaluating Models with Multiple Sampling Strategies...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "### Evaluating with RANDOM sampling ###\n",
      "  Evaluating Static GCN...\n",
      "  Evaluating GRAND (Diffusion)...\n",
      "  Evaluating GREAD (React-Diff)...\n",
      "  Evaluating InnoVelo (Full)...\n",
      "  Evaluating InnoVelo (No Decay)...\n",
      "  Evaluating InnoVelo (No Velocity)...\n",
      "\n",
      "### Evaluating with HISTORICAL sampling ###\n",
      "  Evaluating Static GCN...\n",
      "  Evaluating GRAND (Diffusion)...\n",
      "  Evaluating GREAD (React-Diff)...\n",
      "  Evaluating InnoVelo (Full)...\n",
      "  Evaluating InnoVelo (No Decay)...\n",
      "  Evaluating InnoVelo (No Velocity)...\n",
      "\n",
      "### Evaluating with INDUCTIVE sampling ###\n",
      "  Evaluating Static GCN...\n",
      "  Evaluating GRAND (Diffusion)...\n",
      "  Evaluating GREAD (React-Diff)...\n",
      "  Evaluating InnoVelo (Full)...\n",
      "  Evaluating InnoVelo (No Decay)...\n",
      "  Evaluating InnoVelo (No Velocity)...\n",
      "\n",
      "STEP 6: Visualizing Results and Summarizing...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Saved: sampling_strategy_comparison.png and sampling_strategy_comparison.pdf\n",
      "\n",
      "====================================================================================================\n",
      "MODEL COMPARISON SUMMARY (BY SAMPLING STRATEGY)\n",
      "====================================================================================================\n",
      "                                  1_step_AUC         1_step_AP          \\\n",
      "                                        mean     std      mean     std   \n",
      "model                  sampling                                          \n",
      "GRAND (Diffusion)      historical     0.9003  0.0023    0.9104  0.0052   \n",
      "                       inductive      0.9002  0.0024    0.9103  0.0054   \n",
      "                       random         0.9002  0.0024    0.9104  0.0055   \n",
      "GREAD (React-Diff)     historical     0.8642  0.0219    0.8971  0.0091   \n",
      "                       inductive      0.8643  0.0222    0.8972  0.0093   \n",
      "                       random         0.8643  0.0221    0.8971  0.0092   \n",
      "InnoVelo (Full)        historical     0.6830  0.1009    0.7350  0.0656   \n",
      "                       inductive      0.6827  0.1012    0.7349  0.0659   \n",
      "                       random         0.6829  0.1009    0.7349  0.0657   \n",
      "InnoVelo (No Decay)    historical     0.6719  0.0999    0.7269  0.0635   \n",
      "                       inductive      0.6720  0.1001    0.7269  0.0636   \n",
      "                       random         0.6719  0.0998    0.7269  0.0634   \n",
      "InnoVelo (No Velocity) historical     0.8338  0.0476    0.8388  0.0452   \n",
      "                       inductive      0.8339  0.0477    0.8387  0.0451   \n",
      "                       random         0.8339  0.0477    0.8386  0.0454   \n",
      "Static GCN             historical     0.8464  0.0344    0.8769  0.0189   \n",
      "                       inductive      0.8462  0.0345    0.8767  0.0191   \n",
      "                       random         0.8462  0.0346    0.8769  0.0191   \n",
      "\n",
      "                                  2_step_AUC         2_step_AP          \n",
      "                                        mean     std      mean     std  \n",
      "model                  sampling                                         \n",
      "GRAND (Diffusion)      historical     0.8695  0.0142    0.8847  0.0088  \n",
      "                       inductive      0.8694  0.0143    0.8847  0.0090  \n",
      "                       random         0.8694  0.0144    0.8848  0.0090  \n",
      "GREAD (React-Diff)     historical     0.8393  0.0329    0.8758  0.0190  \n",
      "                       inductive      0.8391  0.0329    0.8757  0.0190  \n",
      "                       random         0.8393  0.0328    0.8759  0.0189  \n",
      "InnoVelo (Full)        historical     0.7081  0.0827    0.7523  0.0532  \n",
      "                       inductive      0.7082  0.0827    0.7525  0.0532  \n",
      "                       random         0.7084  0.0823    0.7525  0.0531  \n",
      "InnoVelo (No Decay)    historical     0.6966  0.0819    0.7435  0.0509  \n",
      "                       inductive      0.6968  0.0819    0.7436  0.0510  \n",
      "                       random         0.6966  0.0822    0.7436  0.0510  \n",
      "InnoVelo (No Velocity) historical     0.8339  0.0484    0.8427  0.0426  \n",
      "                       inductive      0.8341  0.0481    0.8429  0.0424  \n",
      "                       random         0.8338  0.0484    0.8427  0.0427  \n",
      "Static GCN             historical     0.8294  0.0430    0.8579  0.0283  \n",
      "                       inductive      0.8294  0.0432    0.8578  0.0286  \n",
      "                       random         0.8294  0.0432    0.8579  0.0286  \n",
      "====================================================================================================\n",
      "\n",
      "✓ Saved: evaluation_results_enhanced.csv, summary_results_enhanced.csv\n",
      "\n",
      "STEP 7: Detailed Visualization for InnoVelo (Full)...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Sampling 3000 out of 169383 nodes for visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/innovelo_full_streamline.png and visualizations_output/innovelo_full_streamline.pdf\n",
      "Sampling 3000 out of 169383 nodes for visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/innovelo_full_velocity_components.png and visualizations_output/innovelo_full_velocity_components.pdf\n",
      "\n",
      "STEP 8: Graph Structure Visualization (Top Category)...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Generating Subgraph Visualization for Category arxiv cs na...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_0.png and visualizations_output/subgraph_cat_0.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs mm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_1.png and visualizations_output/subgraph_cat_1.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs lo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_2.png and visualizations_output/subgraph_cat_2.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs cy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_3.png and visualizations_output/subgraph_cat_3.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs cr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_4.png and visualizations_output/subgraph_cat_4.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs dc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_5.png and visualizations_output/subgraph_cat_5.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs hc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_6.png and visualizations_output/subgraph_cat_6.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ce...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_7.png and visualizations_output/subgraph_cat_7.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ni...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_8.png and visualizations_output/subgraph_cat_8.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs cc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_9.png and visualizations_output/subgraph_cat_9.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ai...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_10.png and visualizations_output/subgraph_cat_10.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ma...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_11.png and visualizations_output/subgraph_cat_11.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs gl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_12.png and visualizations_output/subgraph_cat_12.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ne...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_13.png and visualizations_output/subgraph_cat_13.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs sc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_14.png and visualizations_output/subgraph_cat_14.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_15.png and visualizations_output/subgraph_cat_15.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs cv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_16.png and visualizations_output/subgraph_cat_16.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs gr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_17.png and visualizations_output/subgraph_cat_17.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs et...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_18.png and visualizations_output/subgraph_cat_18.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs sy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_19.png and visualizations_output/subgraph_cat_19.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs cg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_20.png and visualizations_output/subgraph_cat_20.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs oh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_21.png and visualizations_output/subgraph_cat_21.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs pl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_22.png and visualizations_output/subgraph_cat_22.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs se...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_23.png and visualizations_output/subgraph_cat_23.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs lg...\n",
      "No citation links found within the top 100 papers of Category 24.\n",
      "Generating Subgraph Visualization for Category arxiv cs sd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_25.png and visualizations_output/subgraph_cat_25.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs si...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_26.png and visualizations_output/subgraph_cat_26.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ro...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_27.png and visualizations_output/subgraph_cat_27.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_28.png and visualizations_output/subgraph_cat_28.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs pf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_29.png and visualizations_output/subgraph_cat_29.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs cl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_30.png and visualizations_output/subgraph_cat_30.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ir...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_31.png and visualizations_output/subgraph_cat_31.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_32.png and visualizations_output/subgraph_cat_32.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs fl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_33.png and visualizations_output/subgraph_cat_33.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs ds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_34.png and visualizations_output/subgraph_cat_34.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs os...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_35.png and visualizations_output/subgraph_cat_35.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs gt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_36.png and visualizations_output/subgraph_cat_36.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs db...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_37.png and visualizations_output/subgraph_cat_37.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs dl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_38.png and visualizations_output/subgraph_cat_38.pdf\n",
      "Generating Subgraph Visualization for Category arxiv cs dm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1499927/3476732476.py:1010: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = plt.cm.get_cmap('YlOrRd')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: visualizations_output/subgraph_cat_39.png and visualizations_output/subgraph_cat_39.pdf\n",
      "\n",
      "====================================================================================================\n",
      "ALL VISUALIZATIONS COMPLETED!\n",
      "\n",
      "====================================================================================================\n",
      "ALL EXPERIMENTS COMPLETED SUCCESSFULLY!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import umap\n",
    "from scipy.interpolate import griddata\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import sys \n",
    "import csv \n",
    "from contextlib import nullcontext \n",
    "\n",
    "# --- グローバル変数初期化 ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# PDFおよびPNGファイルをまとめるディレクトリ作成\n",
    "OUTPUT_DIR = \"visualizations_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) \n",
    "print(f\"✓ Output directory created: {OUTPUT_DIR}\")\n",
    "\n",
    "# OGBロード時の 'maximum recursion depth exceeded' エラー対策\n",
    "sys.setrecursionlimit(3000) \n",
    "\n",
    "# PyTorch 2.6のセキュリティ制限解除パッチ\n",
    "_original_load = torch.load\n",
    "def unsafe_load(*args, **kwargs):\n",
    "    if 'weights_only' not in kwargs:\n",
    "        kwargs['weights_only'] = False\n",
    "    return _original_load(*args, **kwargs)\n",
    "torch.load = unsafe_load\n",
    "\n",
    "# --- OGBマッピングの動的ロード ---\n",
    "try:\n",
    "    from ogb.nodeproppred import PygNodePropPredDataset\n",
    "    # マッピングパス取得のため一時的にインスタンス化を試みる\n",
    "    try:\n",
    "        dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='./data')\n",
    "        mapping_path = os.path.join(dataset.root, 'mapping', 'labelidx2arxivcategeory.csv.gz')\n",
    "        label_df = pd.read_csv(mapping_path)\n",
    "        ARXIV_CATEGORY_NAMES = dict(zip(label_df['label idx'], label_df['arxiv category']))\n",
    "        print(f\"\\n✓ OGB-Arxiv Categories Loaded: {len(ARXIV_CATEGORY_NAMES)} unique labels.\")\n",
    "    except Exception as map_e:\n",
    "        raise Exception(f\"Failed to load map after dataset instance: {map_e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ OGB Category Mapping Load Error: {e}\")\n",
    "    print(\"Using DUMMY Category Names.\")\n",
    "    ARXIV_CATEGORY_NAMES = {i: f'Dummy_Cat_{i}' for i in range(40)}\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. Universal Data Adapter\n",
    "# ==========================================\n",
    "class UniversalDataFactory:\n",
    "    def __init__(self, dataset_name, root_dir='./data'):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def load_data(self):\n",
    "        print(f\"Loading dataset: {self.dataset_name}...\")\n",
    "        try:\n",
    "            from ogb.nodeproppred import PygNodePropPredDataset\n",
    "            dataset = PygNodePropPredDataset(name='ogbn-arxiv', root=self.root_dir)\n",
    "            data = dataset[0]\n",
    "            print(f\"✓ Loaded OGB dataset successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"OGB Load Error: {e}. Creating DUMMY data for demo.\")\n",
    "            num_nodes = 2000\n",
    "            edge_index = torch.randint(0, num_nodes, (2, 10000))\n",
    "            x = torch.randn(num_nodes, 128)\n",
    "            y = torch.randint(0, 40, (num_nodes,))\n",
    "            node_year = torch.randint(2015, 2021, (num_nodes, 1))\n",
    "            data = Data(x=x, edge_index=edge_index, y=y.unsqueeze(1), node_year=node_year)\n",
    "\n",
    "        num_papers = data.num_nodes\n",
    "        categories = data.y.numpy().flatten()\n",
    "        df_nodes = pd.DataFrame({\n",
    "            'node_id': range(num_papers),\n",
    "            'year': data.node_year.numpy().flatten(),\n",
    "            'category': categories\n",
    "        })\n",
    "        edge_index = data.edge_index.numpy()\n",
    "        df_edges = pd.DataFrame({'source': edge_index[0], 'target': edge_index[1]})\n",
    "        num_categories = len(np.unique(categories))\n",
    "        \n",
    "        print(f\"✓ Data loaded: {num_papers} papers, {num_categories} categories.\")\n",
    "        return {\n",
    "            'df_nodes': df_nodes,\n",
    "            'df_edges': df_edges,\n",
    "            'node_features': data.x,\n",
    "            'num_categories': num_categories\n",
    "        }\n",
    "\n",
    "class DynamicGraphBuilder:\n",
    "    def __init__(self, adapter_output):\n",
    "        self.data = adapter_output\n",
    "        \n",
    "    def build_snapshots(self):\n",
    "        df_nodes = self.data['df_nodes']\n",
    "        df_edges = self.data['df_edges']\n",
    "        feats = self.data['node_features']\n",
    "        years = sorted(df_nodes['year'].unique())\n",
    "        snapshots = {}\n",
    "        num_cats = self.data['num_categories']\n",
    "        offset = num_cats\n",
    "        \n",
    "        print(\"Building temporal snapshots...\")\n",
    "        \n",
    "        for year in years:\n",
    "            if year < 2015:\n",
    "                continue\n",
    "                \n",
    "            active_papers = df_nodes[df_nodes['year'] <= year]\n",
    "            active_ids = active_papers['node_id'].values\n",
    "            valid_edges = df_edges[\n",
    "                (df_edges['source'].isin(active_ids)) & \n",
    "                (df_edges['target'].isin(active_ids))\n",
    "            ]\n",
    "            \n",
    "            # カテゴリ→論文のエッジ\n",
    "            cat_src = torch.tensor(active_papers['category'].values, dtype=torch.long)\n",
    "            paper_dst = torch.tensor(active_papers['node_id'].values + offset, dtype=torch.long)\n",
    "            \n",
    "            # 論文→論文のエッジ\n",
    "            src_paper = torch.tensor(valid_edges['source'].values + offset, dtype=torch.long)\n",
    "            dst_paper = torch.tensor(valid_edges['target'].values + offset, dtype=torch.long)\n",
    "            \n",
    "            edge_index = torch.cat([\n",
    "                torch.stack([cat_src, paper_dst], dim=0),\n",
    "                torch.stack([src_paper, dst_paper], dim=0)\n",
    "            ], dim=1)\n",
    "            \n",
    "            # ラベル設定\n",
    "            total_nodes = offset + len(df_nodes)\n",
    "            full_y = torch.full((total_nodes,), -1, dtype=torch.long)\n",
    "            full_y[:num_cats] = torch.arange(num_cats)\n",
    "            paper_indices = df_nodes['node_id'].values + offset\n",
    "            paper_cats = df_nodes['category'].values\n",
    "            full_y[paper_indices] = torch.tensor(paper_cats, dtype=torch.long)\n",
    "            \n",
    "            snapshots[year] = Data(\n",
    "                x=feats,\n",
    "                edge_index=edge_index,\n",
    "                num_nodes=total_nodes,\n",
    "                y=full_y\n",
    "            )\n",
    "            \n",
    "        print(f\"✓ Built {len(snapshots)} snapshots.\")\n",
    "        return snapshots, num_cats, feats.shape[1]\n",
    "\n",
    "# ==========================================\n",
    "# 2. Advanced Negative Sampling Strategies\n",
    "# ==========================================\n",
    "class NegativeSampler:\n",
    "    \"\"\"複数のネガティブサンプリング戦略を提供\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_negative_sampling(pos_edge_index, num_nodes, num_samples):\n",
    "        return negative_sampling(pos_edge_index, num_nodes=num_nodes, \n",
    "                                num_neg_samples=num_samples)\n",
    "    \n",
    "    @staticmethod\n",
    "    def historical_negative_sampling(train_edges_history, current_pos_edges, \n",
    "                                     num_nodes, num_samples):\n",
    "        historical_set = set()\n",
    "        for edges in train_edges_history:\n",
    "            src, dst = edges[0].cpu().numpy(), edges[1].cpu().numpy()\n",
    "            historical_set.update(zip(src, dst))\n",
    "        \n",
    "        current_src, current_dst = current_pos_edges[0].cpu().numpy(), current_pos_edges[1].cpu().numpy()\n",
    "        current_set = set(zip(current_src, current_dst))\n",
    "        \n",
    "        historical_negatives = list(historical_set - current_set)\n",
    "        \n",
    "        if len(historical_negatives) < num_samples:\n",
    "            extra_needed = num_samples - len(historical_negatives)\n",
    "            random_neg = negative_sampling(current_pos_edges, num_nodes=num_nodes,\n",
    "                                          num_neg_samples=extra_needed)\n",
    "            \n",
    "            if len(historical_negatives) > 0:\n",
    "                hist_neg_array = np.array(historical_negatives).T\n",
    "                hist_neg_tensor = torch.tensor(hist_neg_array, dtype=torch.long)\n",
    "                return torch.cat([hist_neg_tensor, random_neg], dim=1)\n",
    "            else:\n",
    "                return random_neg\n",
    "        else:\n",
    "            sampled_negatives = random.sample(historical_negatives, num_samples)\n",
    "            neg_array = np.array(sampled_negatives).T\n",
    "            return torch.tensor(neg_array, dtype=torch.long)\n",
    "    \n",
    "    @staticmethod\n",
    "    def inductive_negative_sampling(test_history, current_test_edges, \n",
    "                                    num_nodes, num_samples):\n",
    "        test_historical_set = set()\n",
    "        for edges in test_history:\n",
    "            src, dst = edges[0].cpu().numpy(), edges[1].cpu().numpy()\n",
    "            test_historical_set.update(zip(src, dst))\n",
    "        \n",
    "        current_src, current_dst = current_test_edges[0].cpu().numpy(), current_test_edges[1].cpu().numpy()\n",
    "        current_set = set(zip(current_src, current_dst))\n",
    "        \n",
    "        inductive_negatives = list(test_historical_set - current_set)\n",
    "        \n",
    "        if len(inductive_negatives) < num_samples:\n",
    "            extra_needed = num_samples - len(inductive_negatives)\n",
    "            random_neg = negative_sampling(current_test_edges, num_nodes=num_nodes,\n",
    "                                          num_neg_samples=extra_needed)\n",
    "            \n",
    "            if len(inductive_negatives) > 0:\n",
    "                ind_neg_array = np.array(inductive_negatives).T\n",
    "                ind_neg_tensor = torch.tensor(ind_neg_array, dtype=torch.long)\n",
    "                return torch.cat([ind_neg_tensor, random_neg], dim=1)\n",
    "            else:\n",
    "                return random_neg\n",
    "        else:\n",
    "            sampled_negatives = random.sample(inductive_negatives, num_samples)\n",
    "            neg_array = np.array(sampled_negatives).T\n",
    "            return torch.tensor(neg_array, dtype=torch.long)\n",
    "\n",
    "# ==========================================\n",
    "# 3. Baseline Models \n",
    "# ==========================================\n",
    "\n",
    "class StaticGCN(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(StaticGCN, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.gcn1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, edge_index, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        h = F.relu(self.gcn1(h_all, edge_index))\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return h\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "class GCN_LSTM(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(GCN_LSTM, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.gcn1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def encode_snapshot(self, x, edge_index, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        h = F.relu(self.gcn1(h_all, edge_index))\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return h\n",
    "    \n",
    "    def forward(self, snapshots_data):\n",
    "        embeddings = []\n",
    "        for data in snapshots_data:\n",
    "            z = self.encode_snapshot(data.x, data.edge_index, data.num_nodes)\n",
    "            embeddings.append(z)\n",
    "        \n",
    "        if len(embeddings) > 1:\n",
    "            emb_stack = torch.stack(embeddings, dim=1)\n",
    "            lstm_out, _ = self.lstm(emb_stack)\n",
    "            return lstm_out[:, -1, :]\n",
    "        else:\n",
    "            return embeddings[0]\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.sage1 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.sage2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, edge_index, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        h = F.relu(self.sage1(h_all, edge_index))\n",
    "        h = self.sage2(h, edge_index)\n",
    "        return h\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "class SimpleMemoryGNN(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(SimpleMemoryGNN, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.gcn = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.memory_dim = hidden_dim\n",
    "        self.memory_updater = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.memory = None\n",
    "        \n",
    "    def init_memory(self, num_total_nodes, device):\n",
    "        self.memory = torch.zeros(num_total_nodes, self.memory_dim, device=device)\n",
    "        \n",
    "    def encode(self, x, edge_index, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        h = F.relu(self.gcn(h_all, edge_index))\n",
    "        h_with_memory = self.memory_updater(h, self.memory)\n",
    "        self.memory = h_with_memory.detach()\n",
    "        \n",
    "        return h_with_memory\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "# --- GRAND: Graph Neural Diffusion (Section 3.1) ---\n",
    "class GRANDFunc(nn.Module):\n",
    "    def __init__(self, gnn_layer):\n",
    "        super(GRANDFunc, self).__init__()\n",
    "        self.gnn = gnn_layer\n",
    "        self.edge_index = None\n",
    "\n",
    "    def set_graph_structure(self, edge_index):\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        # 拡散方程式: dH/dt = GNN(H) - H\n",
    "        ax = self.gnn(x, self.edge_index)\n",
    "        return ax - x \n",
    "\n",
    "class GRAND_ODE(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(GRAND_ODE, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        # GRANDはAttentionによる拡散が特徴\n",
    "        self.gnn_layer = GATConv(hidden_dim, hidden_dim, heads=1, concat=False)\n",
    "        self.ode_func = GRANDFunc(self.gnn_layer)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        return h_all\n",
    "\n",
    "    def forward(self, x, edge_index, t_span, num_total_nodes):\n",
    "        z0 = self.encode(x, num_total_nodes)\n",
    "        self.ode_func.set_graph_structure(edge_index)\n",
    "        return odeint(self.ode_func, z0, t_span, method='dopri5')\n",
    "\n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "# --- GREAD: Graph Neural Reaction-Diffusion (Section 3.2) ---\n",
    "class GREADFunc(nn.Module):\n",
    "    def __init__(self, hidden_dim, gnn_layer):\n",
    "        super(GREADFunc, self).__init__()\n",
    "        self.gnn = gnn_layer\n",
    "        self.reaction = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.edge_index = None\n",
    "\n",
    "    def set_graph_structure(self, edge_index):\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        # 反応拡散: dH/dt = Diffusion(H) + Reaction(H)\n",
    "        diffusion = self.gnn(x, self.edge_index) - x\n",
    "        reaction = torch.tanh(self.reaction(x))\n",
    "        return diffusion + reaction\n",
    "\n",
    "class GREAD_ODE(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(GREAD_ODE, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.gnn_layer = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.ode_func = GREADFunc(hidden_dim, self.gnn_layer)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        return h_all\n",
    "\n",
    "    def forward(self, x, edge_index, t_span, num_total_nodes):\n",
    "        z0 = self.encode(x, num_total_nodes)\n",
    "        self.ode_func.set_graph_structure(edge_index)\n",
    "        return odeint(self.ode_func, z0, t_span, method='dopri5')\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "# ==========================================\n",
    "# 4. InnoVeloODE: 2nd Order Implementation (提案手法)\n",
    "# ==========================================\n",
    "\n",
    "class SecondOrderODEFunc(nn.Module):\n",
    "    def __init__(self, hidden_dim, gnn_layer, ablation_mode=None):\n",
    "        super(SecondOrderODEFunc, self).__init__()\n",
    "        self.gnn = gnn_layer\n",
    "        self.ablation_mode = ablation_mode # 'no_velocity', 'no_decay', 'adaptive_decay'\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Adaptive Decay: 減衰係数をノードの状態から学習\n",
    "        self.adaptive_decay_net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fixed_damping = nn.Parameter(torch.tensor(0.5))\n",
    "        self.edge_index = None\n",
    "        \n",
    "        # 可視化用コンポーネント保存\n",
    "        self._store_components = False\n",
    "        self.components = {}\n",
    "\n",
    "    def set_graph_structure(self, edge_index):\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, t, z_augmented):\n",
    "        # z_augmented = [Position H, Velocity V]\n",
    "        dim = z_augmented.shape[1] // 2\n",
    "        h = z_augmented[:, :dim]\n",
    "        v = z_augmented[:, dim:]\n",
    "\n",
    "        # 1. Diffusion Force (復元力): GNN output as target\n",
    "        target_h = self.gnn(h, self.edge_index)\n",
    "        diffusion_force = target_h - h \n",
    "\n",
    "        # 2. Decay/Damping Force (減衰力)\n",
    "        if self.ablation_mode == 'no_decay':\n",
    "            decay_force = torch.zeros_like(v)\n",
    "        elif self.ablation_mode == 'adaptive_decay':\n",
    "            gamma = self.adaptive_decay_net(h)\n",
    "            decay_force = -gamma * v\n",
    "        else: # linear_decay or default\n",
    "            decay_force = -self.fixed_damping * v\n",
    "\n",
    "        # 支配方程式: dH/dt = V, dV/dt = Force\n",
    "        dh_dt = v\n",
    "        \n",
    "        if self.ablation_mode == 'no_velocity':\n",
    "            # 1階ODEとして動作 (GRAND相当)\n",
    "            dh_dt = diffusion_force\n",
    "            dv_dt = torch.zeros_like(v)\n",
    "        else:\n",
    "            dv_dt = diffusion_force + decay_force\n",
    "\n",
    "        if self._store_components:\n",
    "            self.components = {\n",
    "                'dz_dt': dh_dt, # 便宜上、位置の変化速度を保存\n",
    "                'velocity': v,\n",
    "                'diffusion': diffusion_force,\n",
    "                'decay': decay_force\n",
    "            }\n",
    "\n",
    "        return torch.cat([dh_dt, dv_dt], dim=1)\n",
    "    \n",
    "    def set_component_storage(self, status):\n",
    "        self._store_components = status\n",
    "    def get_components(self):\n",
    "        return self.components\n",
    "\n",
    "class InnoVeloODE(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim, use_gat=False, gat_heads=2, ablation_mode='adaptive_decay'):\n",
    "        super(InnoVeloODE, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        \n",
    "        # 初期速度 V0 の推定\n",
    "        self.init_velocity = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        if use_gat:\n",
    "            self.gnn_layer = GATConv(hidden_dim, hidden_dim // gat_heads, heads=gat_heads, concat=True)\n",
    "            print(f\"✓ Using GAT ({gat_heads} heads) - Mode: {ablation_mode}\")\n",
    "        else:\n",
    "            self.gnn_layer = GCNConv(hidden_dim, hidden_dim)\n",
    "            print(f\"✓ Using GCN - Mode: {ablation_mode}\")\n",
    "        \n",
    "        self.ode_func = SecondOrderODEFunc(hidden_dim, self.gnn_layer, ablation_mode=ablation_mode)\n",
    "        \n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        # 初期速度の推定 (トレンドの勢い)\n",
    "        v0 = torch.tanh(self.init_velocity(h_all))\n",
    "        return torch.cat([h_all, v0], dim=1) # [H, V]\n",
    "\n",
    "    def forward(self, x, edge_index, t_span, num_total_nodes):\n",
    "        z0_augmented = self.encode(x, num_total_nodes)\n",
    "        self.ode_func.set_graph_structure(edge_index)\n",
    "        \n",
    "        # ODE積分\n",
    "        z_traj = odeint(self.ode_func, z0_augmented, t_span, method='rk4', rtol=1e-3, atol=1e-3)\n",
    "        return z_traj\n",
    "\n",
    "    def predict_link(self, z_augmented, edge_index):\n",
    "        # リンク予測には位置情報 H (前半部分) のみを使用\n",
    "        h = z_augmented[:, :self.hidden_dim]\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([h[src], h[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "    \n",
    "# ==========================================\n",
    "# 5. Enhanced Evaluation Functions\n",
    "# ==========================================\n",
    "def evaluate_link_prediction_enhanced(model, data_t0, data_t1, device, \n",
    "                                     sampling_strategy='random',\n",
    "                                     train_history=None, test_history=None,\n",
    "                                     model_name=\"Model\"):\n",
    "    \"\"\"拡張評価関数\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_t0 = data_t0.to(device)\n",
    "        data_t1 = data_t1.to(device)\n",
    "        \n",
    "        if isinstance(model, (InnoVeloODE, GRAND_ODE, GREAD_ODE)):\n",
    "            t_span = torch.tensor([0.0, 1.0]).to(device)\n",
    "            z_traj = model(data_t0.x, data_t0.edge_index, t_span, data_t0.num_nodes)\n",
    "            z_pred = z_traj[-1]\n",
    "        elif isinstance(model, GCN_LSTM):\n",
    "            z_pred = model.encode_snapshot(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "        elif isinstance(model, SimpleMemoryGNN):\n",
    "            z_pred = model.encode(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "        else:\n",
    "            z_pred = model.encode(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "        \n",
    "        pos_edge = data_t1.edge_index\n",
    "        \n",
    "        if sampling_strategy == 'random':\n",
    "            neg_edge = NegativeSampler.random_negative_sampling(\n",
    "                pos_edge, data_t1.num_nodes, pos_edge.size(1)\n",
    "            )\n",
    "        elif sampling_strategy == 'historical' and train_history is not None:\n",
    "            neg_edge = NegativeSampler.historical_negative_sampling(\n",
    "                train_history, pos_edge, data_t1.num_nodes, pos_edge.size(1)\n",
    "            )\n",
    "        elif sampling_strategy == 'inductive' and test_history is not None:\n",
    "            neg_edge = NegativeSampler.inductive_negative_sampling(\n",
    "                test_history, pos_edge, data_t1.num_nodes, pos_edge.size(1)\n",
    "            )\n",
    "        else:\n",
    "            neg_edge = NegativeSampler.random_negative_sampling(\n",
    "                pos_edge, data_t1.num_nodes, pos_edge.size(1)\n",
    "            )\n",
    "        \n",
    "        pos_score = model.predict_link(z_pred, pos_edge)\n",
    "        neg_score = model.predict_link(z_pred, neg_edge)\n",
    "        \n",
    "        y_true = torch.cat([\n",
    "            torch.ones_like(pos_score),\n",
    "            torch.zeros_like(neg_score)\n",
    "        ]).cpu().numpy()\n",
    "        y_pred = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "        \n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        ap = average_precision_score(y_true, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'AUC': auc,\n",
    "            'AP': ap,\n",
    "            'pos_score_mean': pos_score.mean().item(),\n",
    "            'neg_score_mean': neg_score.mean().item()\n",
    "        }\n",
    "\n",
    "def evaluate_multi_step_enhanced(model, snapshots, years, device, \n",
    "                                sampling_strategy='random', model_name=\"Model\"):\n",
    "    results = []\n",
    "    \n",
    "    train_history = []\n",
    "    test_history = []\n",
    "    \n",
    "    for i in range(len(years) - 2):\n",
    "        t0, t1, t2 = years[i], years[i+1], years[i+2]\n",
    "        \n",
    "        if i > 0:\n",
    "            train_history.append(snapshots[years[i-1]].edge_index)\n",
    "            test_history.append(snapshots[t1].edge_index)\n",
    "        \n",
    "        metrics_1step = evaluate_link_prediction_enhanced(\n",
    "            model, snapshots[t0], snapshots[t1], device,\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            train_history=train_history if len(train_history) > 0 else None,\n",
    "            test_history=test_history if len(test_history) > 0 else None,\n",
    "            model_name=model_name\n",
    "        )\n",
    "        \n",
    "        metrics_2step = evaluate_link_prediction_enhanced(\n",
    "            model, snapshots[t0], snapshots[t2], device,\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            train_history=train_history if len(train_history) > 0 else None,\n",
    "            test_history=test_history if len(test_history) > 0 else None,\n",
    "            model_name=model_name\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'sampling': sampling_strategy,\n",
    "            'time_window': f\"{t0}->{t1}->{t2}\",\n",
    "            '1_step_AUC': metrics_1step['AUC'],\n",
    "            '1_step_AP': metrics_1step['AP'],\n",
    "            '2_step_AUC': metrics_2step['AUC'],\n",
    "            '2_step_AP': metrics_2step['AP']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# 6. Training Function\n",
    "# ==========================================\n",
    "def train_model(model, snapshots, years, device, epochs=5, lr=0.01, model_name=\"Model\"):\n",
    "    \"\"\"モデルの学習\"\"\"\n",
    "    \n",
    "    if isinstance(model, SimpleMemoryGNN):\n",
    "        model.init_memory(snapshots[years[0]].num_nodes, device)\n",
    "    \n",
    "    # EdgeBankの訓練をスキップ\n",
    "    if not isinstance(model, (StaticGCN, GCN_LSTM, GraphSAGEModel, SimpleMemoryGNN, InnoVeloODE, GRAND_ODE, GREAD_ODE)):\n",
    "        print(f\"Skipping training for non-parametric model: {model_name}.\")\n",
    "        return []\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_years = years[-4:] if len(years) >= 4 else years\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_auc = 0\n",
    "        steps = 0\n",
    "        \n",
    "        for i in range(len(train_years) - 1):\n",
    "            t0, t1 = train_years[i], train_years[i+1]\n",
    "            data_t0 = snapshots[t0].to(device)\n",
    "            data_t1 = snapshots[t1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass\n",
    "            if isinstance(model, (InnoVeloODE, GRAND_ODE, GREAD_ODE)):\n",
    "                t_span = torch.tensor([0.0, 1.0]).to(device)\n",
    "                z_traj = model(data_t0.x, data_t0.edge_index, t_span, data_t0.num_nodes)\n",
    "                z_t1_pred = z_traj[-1]\n",
    "            elif isinstance(model, GCN_LSTM):\n",
    "                z_t1_pred = model.encode_snapshot(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "            else:\n",
    "                z_t1_pred = model.encode(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "            \n",
    "            pos_edge_index = data_t1.edge_index\n",
    "            neg_edge_index = negative_sampling(\n",
    "                pos_edge_index, num_nodes=data_t1.num_nodes,\n",
    "                num_neg_samples=pos_edge_index.size(1)\n",
    "            )\n",
    "            \n",
    "            pos_score = model.predict_link(z_t1_pred, pos_edge_index)\n",
    "            neg_score = model.predict_link(z_t1_pred, neg_edge_index)\n",
    "            \n",
    "            loss = -torch.log(pos_score + 1e-15).mean() - torch.log(1 - neg_score + 1e-15).mean()\n",
    "            \n",
    "            # 運動エネルギー正則化 (InnoVeloODEのみ) - インデントと位置を修正\n",
    "            if isinstance(model, InnoVeloODE) and model.ode_func.ablation_mode != 'no_velocity':\n",
    "                # z_trajは上のifブロックで定義されている\n",
    "                z_final = z_traj[-1]\n",
    "                v_final = z_final[:, model.hidden_dim:] \n",
    "                kinetic_energy = torch.mean(v_final ** 2)\n",
    "                loss += 1.0 * kinetic_energy\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_true = torch.cat([\n",
    "                    torch.ones_like(pos_score),\n",
    "                    torch.zeros_like(neg_score)\n",
    "                ]).cpu().numpy()\n",
    "                y_pred = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "                total_auc += roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "        avg_loss = total_loss / steps if steps > 0 else 0\n",
    "        avg_auc = total_auc / steps if steps > 0 else 0\n",
    "        \n",
    "        history.append({'epoch': epoch+1, 'loss': avg_loss, 'auc': avg_auc})\n",
    "        print(f\"{model_name} - Epoch {epoch+1:02d}/{epochs} | Loss: {avg_loss:.4f} | AUC: {avg_auc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# ==========================================\n",
    "# 7. Streamline Visualizer (瞬時速度場)\n",
    "# ==========================================\n",
    "class StreamlineVisualizer:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.category_names = ARXIV_CATEGORY_NAMES \n",
    "\n",
    "    def _get_embeddings_and_components(self, snapshot):\n",
    "        data = snapshot.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.model, InnoVeloODE):\n",
    "                z0 = self.model.encode(data.x, data.num_nodes)\n",
    "                \n",
    "                # 瞬時速度場（dz/dt）を取得\n",
    "                self.model.ode_func.set_component_storage(True)\n",
    "                dz_dt_t0 = self.model.ode_func(torch.tensor(0.0).to(z0.device), z0)\n",
    "                self.model.ode_func.set_component_storage(False)\n",
    "                \n",
    "                z_start = z0.cpu().numpy()\n",
    "                labels = data.y.cpu().numpy().flatten()\n",
    "                \n",
    "                components_tensor = self.model.ode_func.get_components()\n",
    "                components = {k: v.cpu().numpy() for k, v in components_tensor.items()}\n",
    "                \n",
    "                velocities_t0 = dz_dt_t0.cpu().numpy()\n",
    "            \n",
    "            else:\n",
    "                # ODEモデル以外の場合、ダミー速度場を生成\n",
    "                z_start = self.model.encode(data.x, data.edge_index, data.num_nodes).cpu().numpy()\n",
    "                velocities_t0 = np.random.randn(*z_start.shape) * 0.1 \n",
    "                labels = data.y.cpu().numpy().flatten()\n",
    "                components = {\n",
    "                    'dz_dt': velocities_t0,\n",
    "                    'velocity': velocities_t0 * 0.5,\n",
    "                    'diffusion': velocities_t0 * 0.3,\n",
    "                    'decay': velocities_t0 * 0.2\n",
    "                }\n",
    "            \n",
    "            num_cats = self.model.num_cats\n",
    "            # カテゴリノードのみを抽出\n",
    "            valid_mask = (labels >= 0) & (labels < num_cats) \n",
    "        \n",
    "        z_start = z_start[valid_mask]\n",
    "        labels = labels[valid_mask]\n",
    "        velocities_t0 = velocities_t0[valid_mask]\n",
    "        for k in components:\n",
    "            components[k] = components[k][valid_mask]\n",
    "\n",
    "        if z_start.shape[0] == 0:\n",
    "            return None, None, None, None\n",
    "        \n",
    "        # ノードのサンプリングを導入（最大3000ノード）みやすくするため\n",
    "        num_points = z_start.shape[0]\n",
    "        max_points = 3000  # 最大プロット数を設定\n",
    "        if num_points > max_points:\n",
    "            print(f\"Sampling {max_points} out of {num_points} nodes for visualization...\")\n",
    "            idx = np.random.choice(num_points, max_points, replace=False)\n",
    "            \n",
    "            z_start = z_start[idx]\n",
    "            labels = labels[idx]\n",
    "            velocities_t0 = velocities_t0[idx]\n",
    "            for k in components:\n",
    "                components[k] = components[k][idx]\n",
    "\n",
    "        # UMAPで2次元に圧縮 (n_neighborsを調整)\n",
    "        reducer = umap.UMAP(n_components=2, n_neighbors=min(5, z_start.shape[0]-1), min_dist=0.1, random_state=42)\n",
    "        emb_start = reducer.fit_transform(z_start)\n",
    "        \n",
    "        # 瞬時速度ベクトルをUMAP空間で近似\n",
    "        epsilon = 0.1 \n",
    "        emb_end_approx = reducer.transform(z_start + epsilon * velocities_t0)\n",
    "        velocities_umap = (emb_end_approx - emb_start) / epsilon\n",
    "        \n",
    "        return emb_start, labels, components, velocities_umap\n",
    "\n",
    "    def plot_streamline(self, snapshot, title=\"Tech Trend Streamline\", save_prefix=\"streamline\"):\n",
    "        emb_start, labels, components, velocities_umap = self._get_embeddings_and_components(snapshot)\n",
    "        if emb_start is None:\n",
    "            print(\"No valid data for streamline visualization\")\n",
    "            return\n",
    "\n",
    "        x, y = emb_start[:, 0], emb_start[:, 1]\n",
    "        u, v = velocities_umap[:, 0], velocities_umap[:, 1] \n",
    "        \n",
    "        # Net Velocity (dz/dt) の大きさを計算\n",
    "        net_velocity_magnitude = np.linalg.norm(components['dz_dt'], axis=1)\n",
    "        \n",
    "        min_size = 5\n",
    "        max_size_range = 195\n",
    "\n",
    "        # 1. ノードサイズの動的スケーリング: 速度の大きさに応じてサイズを100から500の範囲でスケーリング\n",
    "        if net_velocity_magnitude.max() > 0:\n",
    "            scaled_size = min_size + max_size_range * (net_velocity_magnitude / net_velocity_magnitude.max())\n",
    "        else:\n",
    "            scaled_size = np.full_like(net_velocity_magnitude, 200)\n",
    "\n",
    "        grid_dim = 50\n",
    "        xi = np.linspace(x.min(), x.max(), grid_dim)\n",
    "        yi = np.linspace(y.min(), y.max(), grid_dim)\n",
    "        \n",
    "        ui = griddata((x, y), u, (xi[None, :], yi[:, None]), method='linear')\n",
    "        vi = griddata((x, y), v, (xi[None, :], yi[:, None]), method='linear')\n",
    "        ui = np.nan_to_num(ui); vi = np.nan_to_num(vi)\n",
    "        \n",
    "        speed_grid = np.sqrt(ui**2 + vi**2)\n",
    "        lw = 3.0 * speed_grid / speed_grid.max() if speed_grid.max() > 0 else 1.0\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 20))\n",
    "        unique_labels = np.unique(labels)\n",
    "        \n",
    "        colors = plt.colormaps.get_cmap('tab20c')\n",
    "        \n",
    "        # 修正されたノードサイズを使用\n",
    "        ax.scatter(x, y, c=labels, cmap=colors, s=scaled_size, alpha=0.4, edgecolors='k', linewidths=0.5)\n",
    "        ax.streamplot(xi, yi, ui, vi, color='black', linewidth=lw, arrowsize=1.5, density=1.0, cmap='plasma')\n",
    "        \n",
    "        # 2. ラベルの強調\n",
    "        for label in unique_labels:\n",
    "            mask = (labels == label)\n",
    "            if np.sum(mask) > 0:\n",
    "                cx = np.mean(x[mask]); cy = np.mean(y[mask])\n",
    "                cat_id_str = str(int(label))\n",
    "                ax.text(cx, cy, cat_id_str, fontsize=12, fontweight='bold', \n",
    "                        bbox=dict(boxstyle=\"round,pad=0.5\", fc='white', alpha=0.9, \n",
    "                                  ec=colors(label), linewidth=2)) # 外枠を強調\n",
    "\n",
    "        # 保存パスにディレクトリを付加\n",
    "        final_save_path = os.path.join(OUTPUT_DIR, save_prefix)\n",
    "\n",
    "        # Raw f-stringによるLaTeXタイトルの表示 (最終修正版)\n",
    "        ax.set_title(rf\"{title} (Instantaneous Velocity Field: $\\frac{{dz}}{{dt}}|_{{t=0}}$)\", fontsize=18, pad=20)\n",
    "        ax.set_xlabel(\"UMAP Dimension 1\")\n",
    "        ax.set_ylabel(\"UMAP Dimension 2\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{final_save_path}.png\", dpi=300); plt.savefig(f\"{final_save_path}.pdf\", bbox_inches='tight')\n",
    "        print(f\"Saved: {final_save_path}.png and {final_save_path}.pdf\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    def plot_velocity_components(self, snapshot, title_suffix=\"Velocity Components\", \n",
    "                                 save_prefix=\"velocity_components\"):\n",
    "        emb_start, labels, components, _ = self._get_embeddings_and_components(snapshot)\n",
    "        if emb_start is None:\n",
    "            print(\"No valid data for velocity components visualization\")\n",
    "            return\n",
    "\n",
    "        x, y = emb_start[:, 0], emb_start[:, 1]\n",
    "        \n",
    "        plot_data = {\n",
    "            'Net Velocity (dz/dt)': np.linalg.norm(components['dz_dt'], axis=1),\n",
    "            'Diffusion (GNN)': np.linalg.norm(components['diffusion'], axis=1),\n",
    "            'Intrinsic Velocity': np.linalg.norm(components['velocity'], axis=1),\n",
    "        }\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        min_size = 5\n",
    "        max_size_range = 195\n",
    "        \n",
    "        for ax, (comp_name, comp_magnitude) in zip(axes, plot_data.items()):\n",
    "            if comp_magnitude.max() > 0:\n",
    "                norm_magnitude = comp_magnitude / comp_magnitude.max()\n",
    "            else:\n",
    "                norm_magnitude = comp_magnitude\n",
    "            \n",
    "            # ここでもノードサイズを動的に変更\n",
    "            scaled_size = min_size + max_size_range * (norm_magnitude)\n",
    "            \n",
    "            scatter = ax.scatter(x, y, c=comp_magnitude, cmap='viridis',\n",
    "                               s=scaled_size, alpha=0.5,\n",
    "                               edgecolors='k', linewidths=0.5)\n",
    "            \n",
    "            fig.colorbar(scatter, ax=ax, label='Magnitude (Strength)')\n",
    "            ax.set_title(comp_name)\n",
    "            ax.set_xlabel(\"UMAP Dimension 1\")\n",
    "            ax.set_ylabel(\"UMAP Dimension 2\")\n",
    "\n",
    "        final_save_path = os.path.join(OUTPUT_DIR, save_prefix)\n",
    "\n",
    "        plt.suptitle(f\"Velocity Field Components Analysis - {title_suffix}\", fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"{final_save_path}.png\", dpi=300); plt.savefig(f\"{final_save_path}.pdf\", bbox_inches='tight')\n",
    "        print(f\"Saved: {final_save_path}.png and {final_save_path}.pdf\")\n",
    "        plt.close(fig)\n",
    "\n",
    "# ==========================================\n",
    "# 8. Graph Structure Visualizer\n",
    "# ==========================================\n",
    "class GraphStructureVisualizer:\n",
    "    def __init__(self, df_nodes, df_edges):\n",
    "        self.df_nodes = df_nodes\n",
    "        self.df_edges = df_edges\n",
    "        self.category_names = ARXIV_CATEGORY_NAMES \n",
    "        \n",
    "    def plot_category_subgraph(self, category_id, num_papers=100):\n",
    "        cat_name = self.category_names.get(category_id, f'Cat {category_id}')\n",
    "        print(f\"Generating Subgraph Visualization for Category {cat_name}...\")\n",
    "        \n",
    "        category_papers = self.df_nodes[self.df_nodes['category'] == category_id]\n",
    "        if category_papers.empty:\n",
    "            print(f\"Category {category_id} not found.\")\n",
    "            return\n",
    "\n",
    "        category_papers = category_papers.sort_values(by='year', ascending=False).head(num_papers)\n",
    "        paper_ids = set(category_papers['node_id'].values)\n",
    "        sub_edges = self.df_edges[\n",
    "            (self.df_edges['source'].isin(paper_ids)) & \n",
    "            (self.df_edges['target'].isin(paper_ids))\n",
    "        ]\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(sub_edges[['source', 'target']].values)\n",
    "        \n",
    "        if not G.nodes:\n",
    "            print(f\"No citation links found within the top {num_papers} papers of Category {category_id}.\")\n",
    "            return\n",
    "            \n",
    "        node_years = category_papers.set_index('node_id')['year'].to_dict()\n",
    "        nx.set_node_attributes(G, node_years, 'year')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 20))\n",
    "        pos = nx.spring_layout(G, k=0.15, iterations=50, seed=42)\n",
    "        years_list = [G.nodes[n]['year'] for n in G.nodes if 'year' in G.nodes[n]]\n",
    "        \n",
    "        if not years_list:\n",
    "             cmap = plt.cm.get_cmap('YlOrRd')\n",
    "             norm = plt.Normalize(vmin=0, vmax=1)\n",
    "        else:\n",
    "             cmap = plt.cm.get_cmap('YlOrRd')\n",
    "             norm = plt.Normalize(vmin=min(years_list), vmax=max(years_list))\n",
    "             node_colors = years_list\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos, node_size=150, node_color=years_list, \n",
    "                              cmap=cmap, edgecolors='gray', linewidths=0.5, ax=ax)\n",
    "        nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=10, \n",
    "                              edge_color='gray', alpha=0.6, ax=ax)\n",
    "        node_labels = {node: str(node) for node in G.nodes()}\n",
    "        nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8, font_color='black', ax=ax)\n",
    "        \n",
    "        if years_list:\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array(years_list)\n",
    "            plt.colorbar(sm, ax=ax, orientation='vertical', label='Publication Year')\n",
    "\n",
    "        ax.set_title(f\"Citation Subgraph: {cat_name} (Top {num_papers} Papers)\", \n",
    "                    fontsize=20)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        final_file_prefix = os.path.join(OUTPUT_DIR, f\"subgraph_cat_{category_id}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{final_file_prefix}.png\", dpi=300)\n",
    "        plt.savefig(f\"{final_file_prefix}.pdf\", bbox_inches='tight')\n",
    "        print(f\"Saved: {final_file_prefix}.png and {final_file_prefix}.pdf\")\n",
    "        plt.close(fig)\n",
    "\n",
    "# ==========================================\n",
    "# 9. Results Comparison & Visualization\n",
    "# ==========================================\n",
    "def plot_sampling_comparison(all_results, save_prefix=\"sampling_comparison\"):\n",
    "    \"\"\"複数のサンプリング戦略での比較可視化\"\"\"\n",
    "    sampling_strategies = all_results['sampling'].unique()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "    metrics = ['1_step_AUC', '1_step_AP', '2_step_AUC', '2_step_AP']\n",
    "    titles = ['1-Step AUC', '1-Step AP', '2-Step AUC', '2-Step AP']\n",
    "    \n",
    "    for ax, metric, title in zip(axes.flat, metrics, titles):\n",
    "        for strategy in sampling_strategies:\n",
    "            strategy_data = all_results[all_results['sampling'] == strategy]\n",
    "            for model_name in strategy_data['model'].unique():\n",
    "                model_data = strategy_data[strategy_data['model'] == model_name]\n",
    "                label = f\"{model_name} ({strategy})\"\n",
    "                linestyle = '-' if strategy == 'random' else '--' if strategy == 'historical' else ':'\n",
    "                ax.plot(range(len(model_data)), model_data[metric], \n",
    "                       marker='o', label=label, linewidth=2, linestyle=linestyle)\n",
    "        \n",
    "        ax.set_xlabel('Time Window Index', fontsize=12)\n",
    "        ax.set_ylabel(title, fontsize=12)\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim([0, 1])\n",
    "    \n",
    "    plt.suptitle('Performance Comparison Across Sampling Strategies', fontsize=16, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_prefix}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"{save_prefix}.pdf\", bbox_inches='tight')\n",
    "    print(f\"Saved: {save_prefix}.png and {save_prefix}.pdf\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def print_summary_table(all_results):\n",
    "    \"\"\"結果の要約表を出力\"\"\"\n",
    "    summary = all_results.groupby(['model', 'sampling']).agg({\n",
    "        '1_step_AUC': ['mean', 'std'],\n",
    "        '1_step_AP': ['mean', 'std'],\n",
    "        '2_step_AUC': ['mean', 'std'],\n",
    "        '2_step_AP': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL COMPARISON SUMMARY (BY SAMPLING STRATEGY)\")\n",
    "    print(\"=\"*100)\n",
    "    print(summary)\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# ==========================================\n",
    "# 10. Main Execution Pipeline\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"DYNAMIC GRAPH LEARNING WITH ADVANCED EVALUATION\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    # ハイパーパラメータ\n",
    "    HIDDEN_DIM = 32\n",
    "    EPOCHS = 5\n",
    "    LR = 0.01\n",
    "    USE_GAT = True\n",
    "    GAT_HEADS = 2   \n",
    "    \n",
    "    # 評価するサンプリング戦略\n",
    "    SAMPLING_STRATEGIES = ['random', 'historical', 'inductive']\n",
    "    \n",
    "    # 1. データロード\n",
    "    print(\"STEP 1: Loading Data...\")\n",
    "    factory = UniversalDataFactory('ogbn-arxiv')\n",
    "    raw_data = factory.load_data()\n",
    "    \n",
    "    # 2. グラフ構築\n",
    "    print(\"\\nSTEP 2: Building Dynamic Graphs...\")\n",
    "    builder = DynamicGraphBuilder(raw_data)\n",
    "    snapshots, num_cats, feat_dim = builder.build_snapshots()\n",
    "    years = sorted(snapshots.keys())\n",
    "    \n",
    "    if len(years) < 2:\n",
    "        print(\"Error: Not enough time steps for training.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✓ Time snapshots: {years}\")\n",
    "    print(f\"✓ Categories: {num_cats}, Feature dim: {feat_dim}\")\n",
    "    \n",
    "    # 3. モデル初期化\n",
    "    print(\"\\nSTEP 3: Initializing Models (Baselines & Ablation)...\")\n",
    "    models = {\n",
    "        'Static GCN': StaticGCN(num_cats, feat_dim, HIDDEN_DIM).to(device),\n",
    "        'GRAND (Diffusion)': GRAND_ODE(num_cats, feat_dim, HIDDEN_DIM).to(device),\n",
    "        'GREAD (React-Diff)': GREAD_ODE(num_cats, feat_dim, HIDDEN_DIM).to(device),\n",
    "        \n",
    "        # --- InnoVeloODE Ablation Studies ---\n",
    "        'InnoVelo (Full)': InnoVeloODE(\n",
    "            num_cats, feat_dim, HIDDEN_DIM, use_gat=USE_GAT, gat_heads=GAT_HEADS,\n",
    "            ablation_mode='adaptive_decay'\n",
    "        ).to(device),\n",
    "        \n",
    "        'InnoVelo (No Decay)': InnoVeloODE(\n",
    "            num_cats, feat_dim, HIDDEN_DIM, use_gat=USE_GAT, gat_heads=GAT_HEADS,\n",
    "            ablation_mode='no_decay'\n",
    "        ).to(device),\n",
    "        \n",
    "        'InnoVelo (No Velocity)': InnoVeloODE(\n",
    "            num_cats, feat_dim, HIDDEN_DIM, use_gat=USE_GAT, gat_heads=GAT_HEADS,\n",
    "            ablation_mode='no_velocity'\n",
    "        ).to(device)\n",
    "    }\n",
    "    \n",
    "    for name in models.keys():\n",
    "        print(f\"  ✓ {name}\")\n",
    "    \n",
    "    # 4. 学習\n",
    "    print(\"\\nSTEP 4: Training Models...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        train_model(model, snapshots, years, device, \n",
    "                             epochs=EPOCHS, lr=LR, model_name=name)\n",
    "    \n",
    "    # 5. 複数のサンプリング戦略での評価\n",
    "    print(\"\\nSTEP 5: Evaluating Models with Multiple Sampling Strategies...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    all_results = []\n",
    "    for strategy in SAMPLING_STRATEGIES:\n",
    "        print(f\"\\n### Evaluating with {strategy.upper()} sampling ###\")\n",
    "        for name, model in models.items():\n",
    "            print(f\"  Evaluating {name}...\")\n",
    "            results = evaluate_multi_step_enhanced(\n",
    "                model, snapshots, years, device, \n",
    "                sampling_strategy=strategy, model_name=name\n",
    "            )\n",
    "            all_results.append(results)\n",
    "    \n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # 6. 結果の可視化と要約\n",
    "    print(\"\\nSTEP 6: Visualizing Results and Summarizing...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    plot_sampling_comparison(all_results_df, \"sampling_strategy_comparison\")\n",
    "    summary = print_summary_table(all_results_df)\n",
    "    \n",
    "    all_results_df.to_csv(\"evaluation_results_enhanced.csv\", index=False)\n",
    "    summary.to_csv(\"summary_results_enhanced.csv\")\n",
    "    print(\"✓ Saved: evaluation_results_enhanced.csv, summary_results_enhanced.csv\")\n",
    "    \n",
    "    # 7. Neural ODE (GAT版) の詳細可視化\n",
    "    print(\"\\nSTEP 7: Detailed Visualization for InnoVelo (Full)...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    ode_gat_model = models['InnoVelo (Full)']\n",
    "    latest_snapshot = snapshots[years[-1]]\n",
    "    \n",
    "    visualizer = StreamlineVisualizer(ode_gat_model, device)\n",
    "    visualizer.plot_streamline(latest_snapshot, \n",
    "                              title=\"InnoVelo (Full): Tech Trend Streamline\",\n",
    "                              save_prefix=\"innovelo_full_streamline\")\n",
    "    visualizer.plot_velocity_components(latest_snapshot,\n",
    "                                       title_suffix=\"InnoVelo (Full)\",\n",
    "                                       save_prefix=\"innovelo_full_velocity_components\")\n",
    "    \n",
    "    \n",
    "    # 9. グラフ構造の可視化 (Top Category)\n",
    "    print(\"\\nSTEP 8: Graph Structure Visualization (Top Category)...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    graph_viz = GraphStructureVisualizer(raw_data['df_nodes'], raw_data['df_edges'])\n",
    "\n",
    "    ALL_CATEGORIES = range(40)\n",
    "\n",
    "    for category_id in ALL_CATEGORIES:\n",
    "        graph_viz.plot_category_subgraph(category_id=category_id, num_papers=100)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ALL VISUALIZATIONS COMPLETED!\")\n",
    "    \n",
    "    # 10. 重要な発見の要約\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ALL EXPERIMENTS COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d3d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
