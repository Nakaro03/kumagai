{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995ac52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ogb in /home/nakamuraroi/.local/lib/python3.8/site-packages (1.3.6)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (1.3.2)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /usr/lib/python3/dist-packages (from ogb) (1.25.8)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from ogb) (1.14.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (2.4.1)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from ogb) (0.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: networkx in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.105)\n",
      "Requirement already satisfied: sympy in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (1.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (4.13.2)\n",
      "Requirement already satisfied: filelock in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.16.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (2.20.5)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (9.1.0.70)\n",
      "Requirement already satisfied: fsspec in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch>=1.6.0->ogb) (12.1.3.1)\n",
      "Requirement already satisfied: littleutils in /home/nakamuraroi/.local/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=44 in /usr/lib/python3/dist-packages (from outdated>=0.2.0->ogb) (45.2.0)\n",
      "Requirement already satisfied: requests in /home/nakamuraroi/.local/lib/python3.8/site-packages (from outdated>=0.2.0->ogb) (2.32.4)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.6.0->ogb) (12.9.86)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->outdated>=0.2.0->ogb) (2019.11.28)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from requests->outdated>=0.2.0->ogb) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->outdated>=0.2.0->ogb) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b26bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /home/nakamuraroi/.local/lib/python3.8/site-packages (2.6.1)\n",
      "Requirement already satisfied: fsspec in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (2024.9.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (7.1.3)\n",
      "Requirement already satisfied: jinja2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (1.24.4)\n",
      "Requirement already satisfied: pyparsing in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (3.1.4)\n",
      "Requirement already satisfied: tqdm in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (2.32.4)\n",
      "Requirement already satisfied: aiohttp in /home/nakamuraroi/.local/lib/python3.8/site-packages (from torch_geometric) (3.10.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from jinja2->torch_geometric) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2019.11.28)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from requests->torch_geometric) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torch_geometric) (2.8)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.15.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->torch_geometric) (19.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (2.4.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0; python_version < \"3.11\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/nakamuraroi/.local/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0; python_version < \"3.11\" in /home/nakamuraroi/.local/lib/python3.8/site-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23a3d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データをロード中（パッチ適用済み）...\n",
      "--------------------------------\n",
      "【セットアップ完了】\n",
      "ノード数: 169343\n",
      "特徴量次元: 128\n",
      "これでNeural ODEの実装に進めます。\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "import functools\n",
    "\n",
    "# --- 【緊急パッチ】PyTorch 2.6のセキュリティ制限を解除 ---\n",
    "_original_load = torch.load\n",
    "\n",
    "def unsafe_load(*args, **kwargs):\n",
    "    # 強制的にセキュリティチェックを無効化 (weights_only=False)\n",
    "    if 'weights_only' not in kwargs:\n",
    "        kwargs['weights_only'] = False\n",
    "    return _original_load(*args, **kwargs)\n",
    "\n",
    "torch.load = unsafe_load\n",
    "# -------------------------------------------------------\n",
    "\n",
    "print(\"データをロード中（パッチ適用済み）...\")\n",
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='./data')\n",
    "data = dataset[0]\n",
    "\n",
    "# パッチを戻す（念のため）\n",
    "torch.load = _original_load\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(\"【セットアップ完了】\")\n",
    "print(f\"ノード数: {data.num_nodes}\")\n",
    "print(f\"特徴量次元: {data.x.shape[1]}\")\n",
    "print(\"これでNeural ODEの実装に進めます。\")\n",
    "print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76420886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== データの全体像 ===\n",
      "Data(num_nodes=169343, edge_index=[2, 1166243], x=[169343, 128], node_year=[169343, 1], y=[169343, 1])\n",
      "\n",
      "=== 論文の特徴量（最初の5件） ===\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.057943 -0.052530 -0.072603 -0.026555  0.130435 -0.241386 -0.449242   \n",
      "1 -0.124500 -0.070665 -0.325202  0.007779 -0.001559  0.074189 -0.191013   \n",
      "2 -0.080242 -0.023328 -0.183787 -0.180707  0.075765 -0.125818 -0.394573   \n",
      "3 -0.145044  0.054915 -0.126666  0.039971 -0.055909 -0.101278 -0.339202   \n",
      "4 -0.071154  0.070766 -0.281432 -0.161892 -0.165246 -0.029116 -0.338593   \n",
      "\n",
      "        7         8         9    ...       118       119       120       121  \\\n",
      "0 -0.018443 -0.087218  0.112320  ...  0.211490 -0.226118 -0.185603  0.053230   \n",
      "1  0.049689  0.026369  0.099364  ...  0.106316  0.052926 -0.258378  0.021567   \n",
      "2 -0.219078 -0.108931  0.056966  ...  0.019453 -0.070291 -0.177562 -0.214012   \n",
      "3 -0.115801 -0.080058 -0.001633  ... -0.065752  0.042735  0.066338 -0.226921   \n",
      "4 -0.138727  0.100015  0.132794  ... -0.056130  0.047475 -0.263795  0.026462   \n",
      "\n",
      "        122       123       124       125       126       127  \n",
      "0  0.332873  0.104175  0.007408  0.173364 -0.172796 -0.140059  \n",
      "1  0.281503 -0.173423  0.202082  0.068524 -0.372111 -0.301036  \n",
      "2  0.182186 -0.121589 -0.073642  0.109919  0.117589 -0.139883  \n",
      "3  0.188418 -0.017295  0.063449  0.017816  0.085364 -0.081804  \n",
      "4  0.376349 -0.253772  0.084472  0.098033 -0.075347 -0.111687  \n",
      "\n",
      "[5 rows x 128 columns]\n",
      "\n",
      "=== 引用関係（最初の5リンク） ===\n",
      "          引用元ID   引用先ID\n",
      "0        104447   13091\n",
      "1         15858   47283\n",
      "2        107156   69161\n",
      "3        107156  136440\n",
      "4        107156  107366\n",
      "...         ...     ...\n",
      "1166238   45118   79124\n",
      "1166239   45118  147994\n",
      "1166240   45118  162473\n",
      "1166241   45118  162537\n",
      "1166242   45118   72717\n",
      "\n",
      "[1166243 rows x 2 columns]\n",
      "\n",
      "=== 出版年（最初の5件） ===\n",
      "tensor([2013, 2015, 2014, 2014, 2014])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. データ全体の要約を見る\n",
    "print(\"=== データの全体像 ===\")\n",
    "print(data) \n",
    "\n",
    "# 2. 特徴量（x）の中身を少しだけ見る\n",
    "print(\"\\n=== 論文の特徴量（最初の5件） ===\")\n",
    "# 128個の数字の並びが、1つの論文の意味を表しています\n",
    "df_x = pd.DataFrame(data.x[:5].numpy())\n",
    "print(df_x)\n",
    "\n",
    "# 3. 引用関係（edge_index）の中身を見る\n",
    "print(\"\\n=== 引用関係（最初の5リンク） ===\")\n",
    "# [引用元ID, 引用先ID] のペアです\n",
    "edges = data.edge_index.t()[:]\n",
    "df_edges = pd.DataFrame(edges.numpy(), columns=[\"引用元ID\", \"引用先ID\"])\n",
    "print(df_edges)\n",
    "\n",
    "# 4. 年データを見る\n",
    "print(\"\\n=== 出版年（最初の5件） ===\")\n",
    "print(data.node_year[:5].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f8310a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>引用元ID</th>\n",
       "      <th>引用先ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104447</td>\n",
       "      <td>13091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15858</td>\n",
       "      <td>47283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107156</td>\n",
       "      <td>69161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107156</td>\n",
       "      <td>136440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107156</td>\n",
       "      <td>107366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166238</th>\n",
       "      <td>45118</td>\n",
       "      <td>79124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166239</th>\n",
       "      <td>45118</td>\n",
       "      <td>147994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166240</th>\n",
       "      <td>45118</td>\n",
       "      <td>162473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166241</th>\n",
       "      <td>45118</td>\n",
       "      <td>162537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166242</th>\n",
       "      <td>45118</td>\n",
       "      <td>72717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1166243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          引用元ID   引用先ID\n",
       "0        104447   13091\n",
       "1         15858   47283\n",
       "2        107156   69161\n",
       "3        107156  136440\n",
       "4        107156  107366\n",
       "...         ...     ...\n",
       "1166238   45118   79124\n",
       "1166239   45118  147994\n",
       "1166240   45118  162473\n",
       "1166241   45118  162537\n",
       "1166242   45118   72717\n",
       "\n",
       "[1166243 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/nakamuraroi/.local/lib/python3.8/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/nakamuraroi/.local/lib/python3.8/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OGBN-Arxiv カテゴリ ID (0-39) 対照表 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakamuraroi/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Arxiv Category Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>arxiv cs na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>arxiv cs mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>arxiv cs lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>arxiv cs cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>arxiv cs cr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>arxiv cs dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>arxiv cs hc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>arxiv cs ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>arxiv cs ni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>arxiv cs cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>arxiv cs ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>arxiv cs ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>arxiv cs gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>arxiv cs ne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>arxiv cs sc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>arxiv cs ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>arxiv cs cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>arxiv cs gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>arxiv cs et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>arxiv cs sy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>arxiv cs cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>arxiv cs oh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>arxiv cs pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>arxiv cs se</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>arxiv cs lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>arxiv cs sd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>arxiv cs si</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>arxiv cs ro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>arxiv cs it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>arxiv cs pf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>arxiv cs cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>arxiv cs ir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>arxiv cs ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>arxiv cs fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>arxiv cs ds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>arxiv cs os</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>arxiv cs gt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>arxiv cs db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>arxiv cs dl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>arxiv cs dm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID Arxiv Category Code\n",
       "0    0         arxiv cs na\n",
       "1    1         arxiv cs mm\n",
       "2    2         arxiv cs lo\n",
       "3    3         arxiv cs cy\n",
       "4    4         arxiv cs cr\n",
       "5    5         arxiv cs dc\n",
       "6    6         arxiv cs hc\n",
       "7    7         arxiv cs ce\n",
       "8    8         arxiv cs ni\n",
       "9    9         arxiv cs cc\n",
       "10  10         arxiv cs ai\n",
       "11  11         arxiv cs ma\n",
       "12  12         arxiv cs gl\n",
       "13  13         arxiv cs ne\n",
       "14  14         arxiv cs sc\n",
       "15  15         arxiv cs ar\n",
       "16  16         arxiv cs cv\n",
       "17  17         arxiv cs gr\n",
       "18  18         arxiv cs et\n",
       "19  19         arxiv cs sy\n",
       "20  20         arxiv cs cg\n",
       "21  21         arxiv cs oh\n",
       "22  22         arxiv cs pl\n",
       "23  23         arxiv cs se\n",
       "24  24         arxiv cs lg\n",
       "25  25         arxiv cs sd\n",
       "26  26         arxiv cs si\n",
       "27  27         arxiv cs ro\n",
       "28  28         arxiv cs it\n",
       "29  29         arxiv cs pf\n",
       "30  30         arxiv cs cl\n",
       "31  31         arxiv cs ir\n",
       "32  32         arxiv cs ms\n",
       "33  33         arxiv cs fl\n",
       "34  34         arxiv cs ds\n",
       "35  35         arxiv cs os\n",
       "36  36         arxiv cs gt\n",
       "37  37         arxiv cs db\n",
       "38  38         arxiv cs dl\n",
       "39  39         arxiv cs dm"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- OGBマッピングの動的ロード (再現用) ---\n",
    "# 実際のデータが読み込まれていることを確認します。\n",
    "root_dir = './data'\n",
    "mapping_path = os.path.join(root_dir, 'ogbn_arxiv/mapping/labelidx2arxivcategeory.csv.gz')\n",
    "\n",
    "try:\n",
    "    label_df = pd.read_csv(mapping_path)\n",
    "    # IDをキー、カテゴリコードを値とする辞書を作成\n",
    "    ARXIV_CATEGORY_NAMES = dict(zip(label_df['label idx'], label_df['arxiv category']))\n",
    "except Exception:\n",
    "    # 失敗した場合はダミーデータを使用（元のコードのロジックを再現）\n",
    "    ARXIV_CATEGORY_NAMES = {i: f'Dummy_Cat_{i}' for i in range(40)}\n",
    "# ----------------------------------------\n",
    "\n",
    "\n",
    "# IDとカテゴリコードのペアを抽出し、データフレームを作成\n",
    "category_data = []\n",
    "# 0から39までのIDを明示的に処理\n",
    "for cat_id in range(40):\n",
    "    category_code = ARXIV_CATEGORY_NAMES.get(cat_id, 'N/A')\n",
    "    category_data.append([cat_id, category_code])\n",
    "\n",
    "# DataFrameの作成\n",
    "df_categories = pd.DataFrame(category_data, columns=['ID', 'Arxiv Category Code'])\n",
    "\n",
    "print(\"=== OGBN-Arxiv カテゴリ ID (0-39) 対照表 ===\")\n",
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1d02d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✓ Output directory created: visualizations_output\n",
      "⚠️ OGB Category Mapping Load Error: Failed to load map after dataset instance: maximum recursion depth exceeded\n",
      "Using DUMMY Category Names.\n",
      "\n",
      "====================================================================================================\n",
      "DYNAMIC GRAPH LEARNING WITH ADVANCED EVALUATION\n",
      "====================================================================================================\n",
      "\n",
      "STEP 1: Loading Data...\n",
      "Loading dataset: ogbn-arxiv...\n",
      "OGB Load Error: maximum recursion depth exceeded. Creating DUMMY data for demo.\n",
      "✓ Data loaded: 2000 papers, 40 categories.\n",
      "\n",
      "STEP 2: Building Dynamic Graphs...\n",
      "Building temporal snapshots...\n",
      "✓ Built 6 snapshots.\n",
      "✓ Time snapshots: [2015, 2016, 2017, 2018, 2019, 2020]\n",
      "✓ Categories: 40, Feature dim: 128\n",
      "\n",
      "STEP 3: Initializing Models (Baselines & Ablation)...\n",
      "✓ Using GAT (2 heads) - Mode: adaptive_decay\n",
      "✓ Using GAT (2 heads) - Mode: no_decay\n",
      "✓ Using GAT (2 heads) - Mode: no_velocity\n",
      "  ✓ Static GCN\n",
      "  ✓ GRAND (Diffusion)\n",
      "  ✓ GREAD (React-Diff)\n",
      "  ✓ InnoVelo (Full)\n",
      "  ✓ InnoVelo (No Decay)\n",
      "  ✓ InnoVelo (No Velocity)\n",
      "\n",
      "STEP 4: Training Models...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training Static GCN...\n",
      "Static GCN - Epoch 01/5 | Loss: 1.3873 | AUC: 0.5423\n",
      "Static GCN - Epoch 02/5 | Loss: 1.3651 | AUC: 0.6284\n",
      "Static GCN - Epoch 03/5 | Loss: 1.3422 | AUC: 0.6425\n",
      "Static GCN - Epoch 04/5 | Loss: 1.3154 | AUC: 0.6517\n",
      "Static GCN - Epoch 05/5 | Loss: 1.2876 | AUC: 0.6694\n",
      "\n",
      "Training GRAND (Diffusion)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1516\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1516\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 1382\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1379\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m   1381\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1382\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myears\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;66;03m# 5. 複数のサンプリング戦略での評価\u001b[39;00m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSTEP 5: Evaluating Models with Multiple Sampling Strategies...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 916\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, snapshots, years, device, epochs, lr, model_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m     kinetic_energy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(v_final \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    914\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m kinetic_energy\n\u001b[0;32m--> 916\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    919\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import umap\n",
    "from scipy.interpolate import griddata\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import sys \n",
    "import csv \n",
    "from contextlib import nullcontext\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import time\n",
    "\n",
    "# --- グローバル変数初期化 ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# PDFおよびPNGファイルをまとめるディレクトリ作成\n",
    "OUTPUT_DIR = \"visualizations_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) \n",
    "print(f\"✓ Output directory created: {OUTPUT_DIR}\")\n",
    "\n",
    "# OGBロード時の 'maximum recursion depth exceeded' エラー対策\n",
    "sys.setrecursionlimit(3000) \n",
    "\n",
    "# PyTorch 2.6のセキュリティ制限解除パッチ\n",
    "_original_load = torch.load\n",
    "def unsafe_load(*args, **kwargs):\n",
    "    if 'weights_only' not in kwargs:\n",
    "        kwargs['weights_only'] = False\n",
    "    return _original_load(*args, **kwargs)\n",
    "torch.load = unsafe_load\n",
    "\n",
    "# --- OGBマッピングの動的ロード ---\n",
    "try:\n",
    "    from ogb.nodeproppred import PygNodePropPredDataset\n",
    "    # マッピングパス取得のため一時的にインスタンス化を試みる\n",
    "    try:\n",
    "        dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='./data')\n",
    "        mapping_path = os.path.join(dataset.root, 'mapping', 'labelidx2arxivcategeory.csv.gz')\n",
    "        label_df = pd.read_csv(mapping_path)\n",
    "        ARXIV_CATEGORY_NAMES = dict(zip(label_df['label idx'], label_df['arxiv category']))\n",
    "        print(f\"\\n✓ OGB-Arxiv Categories Loaded: {len(ARXIV_CATEGORY_NAMES)} unique labels.\")\n",
    "    except Exception as map_e:\n",
    "        raise Exception(f\"Failed to load map after dataset instance: {map_e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ OGB Category Mapping Load Error: {e}\")\n",
    "    print(\"Using DUMMY Category Names.\")\n",
    "    ARXIV_CATEGORY_NAMES = {i: f'Dummy_Cat_{i}' for i in range(40)}\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 1. Universal Data Adapter\n",
    "# ==========================================\n",
    "class UniversalDataFactory:\n",
    "    def __init__(self, dataset_name, root_dir='./data'):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def load_data(self):\n",
    "        print(f\"Loading dataset: {self.dataset_name}...\")\n",
    "        try:\n",
    "            from ogb.nodeproppred import PygNodePropPredDataset\n",
    "            dataset = PygNodePropPredDataset(name='ogbn-arxiv', root=self.root_dir)\n",
    "            data = dataset[0]\n",
    "            print(f\"✓ Loaded OGB dataset successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"OGB Load Error: {e}. Creating DUMMY data for demo.\")\n",
    "            num_nodes = 2000\n",
    "            edge_index = torch.randint(0, num_nodes, (2, 10000))\n",
    "            x = torch.randn(num_nodes, 128)\n",
    "            y = torch.randint(0, 40, (num_nodes,))\n",
    "            node_year = torch.randint(2015, 2021, (num_nodes, 1))\n",
    "            data = Data(x=x, edge_index=edge_index, y=y.unsqueeze(1), node_year=node_year)\n",
    "\n",
    "        num_papers = data.num_nodes\n",
    "        categories = data.y.numpy().flatten()\n",
    "        df_nodes = pd.DataFrame({\n",
    "            'node_id': range(num_papers),\n",
    "            'year': data.node_year.numpy().flatten(),\n",
    "            'category': categories\n",
    "        })\n",
    "        edge_index = data.edge_index.numpy()\n",
    "        df_edges = pd.DataFrame({'source': edge_index[0], 'target': edge_index[1]})\n",
    "        num_categories = len(np.unique(categories))\n",
    "        \n",
    "        print(f\"✓ Data loaded: {num_papers} papers, {num_categories} categories.\")\n",
    "        return {\n",
    "            'df_nodes': df_nodes,\n",
    "            'df_edges': df_edges,\n",
    "            'node_features': data.x,\n",
    "            'num_categories': num_categories\n",
    "        }\n",
    "\n",
    "class DynamicGraphBuilder:\n",
    "    def __init__(self, adapter_output):\n",
    "        self.data = adapter_output\n",
    "        \n",
    "    def build_snapshots(self):\n",
    "        df_nodes = self.data['df_nodes']\n",
    "        df_edges = self.data['df_edges']\n",
    "        feats = self.data['node_features']\n",
    "        years = sorted(df_nodes['year'].unique())\n",
    "        snapshots = {}\n",
    "        num_cats = self.data['num_categories']\n",
    "        offset = num_cats\n",
    "        \n",
    "        print(\"Building temporal snapshots...\")\n",
    "        \n",
    "        for year in years:\n",
    "            if year < 2015:\n",
    "                continue\n",
    "                \n",
    "            active_papers = df_nodes[df_nodes['year'] <= year]\n",
    "            active_ids = active_papers['node_id'].values\n",
    "            valid_edges = df_edges[\n",
    "                (df_edges['source'].isin(active_ids)) & \n",
    "                (df_edges['target'].isin(active_ids))\n",
    "            ]\n",
    "            \n",
    "            # カテゴリ→論文のエッジ\n",
    "            cat_src = torch.tensor(active_papers['category'].values, dtype=torch.long)\n",
    "            paper_dst = torch.tensor(active_papers['node_id'].values + offset, dtype=torch.long)\n",
    "            \n",
    "            # 論文→論文のエッジ\n",
    "            src_paper = torch.tensor(valid_edges['source'].values + offset, dtype=torch.long)\n",
    "            dst_paper = torch.tensor(valid_edges['target'].values + offset, dtype=torch.long)\n",
    "            \n",
    "            edge_index = torch.cat([\n",
    "                torch.stack([cat_src, paper_dst], dim=0),\n",
    "                torch.stack([src_paper, dst_paper], dim=0)\n",
    "            ], dim=1)\n",
    "            \n",
    "            # ラベル設定\n",
    "            total_nodes = offset + len(df_nodes)\n",
    "            full_y = torch.full((total_nodes,), -1, dtype=torch.long)\n",
    "            full_y[:num_cats] = torch.arange(num_cats)\n",
    "            paper_indices = df_nodes['node_id'].values + offset\n",
    "            paper_cats = df_nodes['category'].values\n",
    "            full_y[paper_indices] = torch.tensor(paper_cats, dtype=torch.long)\n",
    "            \n",
    "            snapshots[year] = Data(\n",
    "                x=feats,\n",
    "                edge_index=edge_index,\n",
    "                num_nodes=total_nodes,\n",
    "                y=full_y\n",
    "            )\n",
    "            \n",
    "        print(f\"✓ Built {len(snapshots)} snapshots.\")\n",
    "        return snapshots, num_cats, feats.shape[1]\n",
    "\n",
    "# ==========================================\n",
    "# 2. Advanced Negative Sampling Strategies\n",
    "# ==========================================\n",
    "class NegativeSampler:\n",
    "    \"\"\"複数のネガティブサンプリング戦略を提供\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_negative_sampling(pos_edge_index, num_nodes, num_samples):\n",
    "        return negative_sampling(pos_edge_index, num_nodes=num_nodes, \n",
    "                                num_neg_samples=num_samples)\n",
    "    \n",
    "    @staticmethod\n",
    "    def historical_negative_sampling(train_edges_history, current_pos_edges, \n",
    "                                     num_nodes, num_samples):\n",
    "        historical_set = set()\n",
    "        for edges in train_edges_history:\n",
    "            src, dst = edges[0].cpu().numpy(), edges[1].cpu().numpy()\n",
    "            historical_set.update(zip(src, dst))\n",
    "        \n",
    "        current_src, current_dst = current_pos_edges[0].cpu().numpy(), current_pos_edges[1].cpu().numpy()\n",
    "        current_set = set(zip(current_src, current_dst))\n",
    "        \n",
    "        historical_negatives = list(historical_set - current_set)\n",
    "        \n",
    "        if len(historical_negatives) < num_samples:\n",
    "            extra_needed = num_samples - len(historical_negatives)\n",
    "            random_neg = negative_sampling(current_pos_edges, num_nodes=num_nodes,\n",
    "                                          num_neg_samples=extra_needed)\n",
    "            \n",
    "            if len(historical_negatives) > 0:\n",
    "                hist_neg_array = np.array(historical_negatives).T\n",
    "                hist_neg_tensor = torch.tensor(hist_neg_array, dtype=torch.long)\n",
    "                return torch.cat([hist_neg_tensor, random_neg], dim=1)\n",
    "            else:\n",
    "                return random_neg\n",
    "        else:\n",
    "            sampled_negatives = random.sample(historical_negatives, num_samples)\n",
    "            neg_array = np.array(sampled_negatives).T\n",
    "            return torch.tensor(neg_array, dtype=torch.long)\n",
    "    \n",
    "    @staticmethod\n",
    "    def inductive_negative_sampling(test_history, current_test_edges, \n",
    "                                    num_nodes, num_samples):\n",
    "        test_historical_set = set()\n",
    "        for edges in test_history:\n",
    "            src, dst = edges[0].cpu().numpy(), edges[1].cpu().numpy()\n",
    "            test_historical_set.update(zip(src, dst))\n",
    "        \n",
    "        current_src, current_dst = current_test_edges[0].cpu().numpy(), current_test_edges[1].cpu().numpy()\n",
    "        current_set = set(zip(current_src, current_dst))\n",
    "        \n",
    "        inductive_negatives = list(test_historical_set - current_set)\n",
    "        \n",
    "        if len(inductive_negatives) < num_samples:\n",
    "            extra_needed = num_samples - len(inductive_negatives)\n",
    "            random_neg = negative_sampling(current_test_edges, num_nodes=num_nodes,\n",
    "                                          num_neg_samples=extra_needed)\n",
    "            \n",
    "            if len(inductive_negatives) > 0:\n",
    "                ind_neg_array = np.array(inductive_negatives).T\n",
    "                ind_neg_tensor = torch.tensor(ind_neg_array, dtype=torch.long)\n",
    "                return torch.cat([ind_neg_tensor, random_neg], dim=1)\n",
    "            else:\n",
    "                return random_neg\n",
    "        else:\n",
    "            sampled_negatives = random.sample(inductive_negatives, num_samples)\n",
    "            neg_array = np.array(sampled_negatives).T\n",
    "            return torch.tensor(neg_array, dtype=torch.long)\n",
    "\n",
    "# ==========================================\n",
    "# 3. Baseline Models \n",
    "# ==========================================\n",
    "\n",
    "class StaticGCN(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(StaticGCN, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.gcn1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, edge_index, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        h = F.relu(self.gcn1(h_all, edge_index))\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return h\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "class GCN_LSTM(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(GCN_LSTM, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.gcn1 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def encode_snapshot(self, x, edge_index, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        h = F.relu(self.gcn1(h_all, edge_index))\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        return h\n",
    "    \n",
    "    def forward(self, snapshots_data):\n",
    "        embeddings = []\n",
    "        for data in snapshots_data:\n",
    "            z = self.encode_snapshot(data.x, data.edge_index, data.num_nodes)\n",
    "            embeddings.append(z)\n",
    "        \n",
    "        if len(embeddings) > 1:\n",
    "            emb_stack = torch.stack(embeddings, dim=1)\n",
    "            lstm_out, _ = self.lstm(emb_stack)\n",
    "            return lstm_out[:, -1, :]\n",
    "        else:\n",
    "            return embeddings[0]\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.sage1 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.sage2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, edge_index, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        h = F.relu(self.sage1(h_all, edge_index))\n",
    "        h = self.sage2(h, edge_index)\n",
    "        return h\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "class SimpleMemoryGNN(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(SimpleMemoryGNN, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.gcn = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.memory_dim = hidden_dim\n",
    "        self.memory_updater = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.memory = None\n",
    "        \n",
    "    def init_memory(self, num_total_nodes, device):\n",
    "        self.memory = torch.zeros(num_total_nodes, self.memory_dim, device=device)\n",
    "        \n",
    "    def encode(self, x, edge_index, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        h = F.relu(self.gcn(h_all, edge_index))\n",
    "        h_with_memory = self.memory_updater(h, self.memory)\n",
    "        self.memory = h_with_memory.detach()\n",
    "        \n",
    "        return h_with_memory\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "# --- GRAND: Graph Neural Diffusion (Section 3.1) ---\n",
    "class GRANDFunc(nn.Module):\n",
    "    def __init__(self, gnn_layer):\n",
    "        super(GRANDFunc, self).__init__()\n",
    "        self.gnn = gnn_layer\n",
    "        self.edge_index = None\n",
    "\n",
    "    def set_graph_structure(self, edge_index):\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        # 拡散方程式: dH/dt = GNN(H) - H\n",
    "        ax = self.gnn(x, self.edge_index)\n",
    "        return ax - x \n",
    "\n",
    "class GRAND_ODE(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(GRAND_ODE, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        # GRANDはAttentionによる拡散が特徴\n",
    "        self.gnn_layer = GATConv(hidden_dim, hidden_dim, heads=1, concat=False)\n",
    "        self.ode_func = GRANDFunc(self.gnn_layer)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        return h_all\n",
    "\n",
    "    def forward(self, x, edge_index, t_span, num_total_nodes):\n",
    "        z0 = self.encode(x, num_total_nodes)\n",
    "        self.ode_func.set_graph_structure(edge_index)\n",
    "        return odeint(self.ode_func, z0, t_span, method='dopri5')\n",
    "\n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "# --- GREAD: Graph Neural Reaction-Diffusion (Section 3.2) ---\n",
    "class GREADFunc(nn.Module):\n",
    "    def __init__(self, hidden_dim, gnn_layer):\n",
    "        super(GREADFunc, self).__init__()\n",
    "        self.gnn = gnn_layer\n",
    "        self.reaction = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.edge_index = None\n",
    "\n",
    "    def set_graph_structure(self, edge_index):\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        # 反応拡散: dH/dt = Diffusion(H) + Reaction(H)\n",
    "        diffusion = self.gnn(x, self.edge_index) - x\n",
    "        reaction = torch.tanh(self.reaction(x))\n",
    "        return diffusion + reaction\n",
    "\n",
    "class GREAD_ODE(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim):\n",
    "        super(GREAD_ODE, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        self.gnn_layer = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.ode_func = GREADFunc(hidden_dim, self.gnn_layer)\n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        return h_all\n",
    "\n",
    "    def forward(self, x, edge_index, t_span, num_total_nodes):\n",
    "        z0 = self.encode(x, num_total_nodes)\n",
    "        self.ode_func.set_graph_structure(edge_index)\n",
    "        return odeint(self.ode_func, z0, t_span, method='dopri5')\n",
    "    \n",
    "    def predict_link(self, z, edge_index):\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([z[src], z[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "\n",
    "# ==========================================\n",
    "# 4. InnoVeloODE: 2nd Order Implementation (提案手法)\n",
    "# ==========================================\n",
    "\n",
    "class SecondOrderODEFunc(nn.Module):\n",
    "    def __init__(self, hidden_dim, gnn_layer, ablation_mode=None):\n",
    "        super(SecondOrderODEFunc, self).__init__()\n",
    "        self.gnn = gnn_layer\n",
    "        self.ablation_mode = ablation_mode # 'no_velocity', 'no_decay', 'adaptive_decay'\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Adaptive Decay: 減衰係数をノードの状態から学習\n",
    "        self.adaptive_decay_net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fixed_damping = nn.Parameter(torch.tensor(0.5))\n",
    "        self.edge_index = None\n",
    "        \n",
    "        # 可視化用コンポーネント保存\n",
    "        self._store_components = False\n",
    "        self.components = {}\n",
    "\n",
    "    def set_graph_structure(self, edge_index):\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, t, z_augmented):\n",
    "        # z_augmented = [Position H, Velocity V]\n",
    "        dim = z_augmented.shape[1] // 2\n",
    "        h = z_augmented[:, :dim]\n",
    "        v = z_augmented[:, dim:]\n",
    "\n",
    "        # 1. Diffusion Force (復元力): GNN output as target\n",
    "        target_h = self.gnn(h, self.edge_index)\n",
    "        diffusion_force = target_h - h \n",
    "\n",
    "        # 2. Decay/Damping Force (減衰力)\n",
    "        if self.ablation_mode == 'no_decay':\n",
    "            decay_force = torch.zeros_like(v)\n",
    "        elif self.ablation_mode == 'adaptive_decay':\n",
    "            gamma = self.adaptive_decay_net(h)\n",
    "            decay_force = -gamma * v\n",
    "        else: # linear_decay or default\n",
    "            decay_force = -self.fixed_damping * v\n",
    "\n",
    "        # 支配方程式: dH/dt = V, dV/dt = Force\n",
    "        dh_dt = v\n",
    "        \n",
    "        if self.ablation_mode == 'no_velocity':\n",
    "            # 1階ODEとして動作 (GRAND相当)\n",
    "            dh_dt = diffusion_force\n",
    "            dv_dt = torch.zeros_like(v)\n",
    "        else:\n",
    "            dv_dt = diffusion_force + decay_force\n",
    "\n",
    "        if self._store_components:\n",
    "            self.components = {\n",
    "                'dz_dt': dh_dt, # 便宜上、位置の変化速度を保存\n",
    "                'velocity': v,\n",
    "                'diffusion': diffusion_force,\n",
    "                'decay': decay_force\n",
    "            }\n",
    "\n",
    "        return torch.cat([dh_dt, dv_dt], dim=1)\n",
    "    \n",
    "    def set_component_storage(self, status):\n",
    "        self._store_components = status\n",
    "    def get_components(self):\n",
    "        return self.components\n",
    "\n",
    "class InnoVeloODE(nn.Module):\n",
    "    def __init__(self, num_cats, feat_dim, hidden_dim, use_gat=False, gat_heads=2, ablation_mode='adaptive_decay'):\n",
    "        super(InnoVeloODE, self).__init__()\n",
    "        self.num_cats = num_cats\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cat_emb = nn.Embedding(num_cats, hidden_dim)\n",
    "        self.feat_encoder = nn.Linear(feat_dim, hidden_dim)\n",
    "        \n",
    "        # 初期速度 V0 の推定\n",
    "        self.init_velocity = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        if use_gat:\n",
    "            self.gnn_layer = GATConv(hidden_dim, hidden_dim // gat_heads, heads=gat_heads, concat=True)\n",
    "            print(f\"✓ Using GAT ({gat_heads} heads) - Mode: {ablation_mode}\")\n",
    "        else:\n",
    "            self.gnn_layer = GCNConv(hidden_dim, hidden_dim)\n",
    "            print(f\"✓ Using GCN - Mode: {ablation_mode}\")\n",
    "        \n",
    "        self.ode_func = SecondOrderODEFunc(hidden_dim, self.gnn_layer, ablation_mode=ablation_mode)\n",
    "        \n",
    "        self.link_decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x, num_total_nodes):\n",
    "        h_paper = self.feat_encoder(x)\n",
    "        h_cat = self.cat_emb.weight\n",
    "        h_all = torch.zeros(num_total_nodes, h_paper.size(1), device=x.device)\n",
    "        h_all[:self.num_cats] = h_cat\n",
    "        h_all[self.num_cats:self.num_cats+h_paper.size(0)] = h_paper\n",
    "        \n",
    "        # 初期速度の推定 (トレンドの勢い)\n",
    "        # v0 = torch.tanh(self.init_velocity(h_all))\n",
    "        v0 = torch.zeros_like(h_all)\n",
    "        return torch.cat([h_all, v0], dim=1) # [H, V]\n",
    "\n",
    "    def forward(self, x, edge_index, t_span, num_total_nodes):\n",
    "        z0_augmented = self.encode(x, num_total_nodes)\n",
    "        self.ode_func.set_graph_structure(edge_index)\n",
    "        \n",
    "        # ODE積分\n",
    "        z_traj = odeint(self.ode_func, z0_augmented, t_span, method='rk4', rtol=1e-3, atol=1e-3)\n",
    "        return z_traj\n",
    "\n",
    "    def predict_link(self, z_augmented, edge_index):\n",
    "        # リンク予測には位置情報 H (前半部分) のみを使用\n",
    "        h = z_augmented[:, :self.hidden_dim]\n",
    "        src, dst = edge_index\n",
    "        cat_feat = torch.cat([h[src], h[dst]], dim=-1)\n",
    "        return torch.sigmoid(self.link_decoder(cat_feat)).view(-1)\n",
    "    \n",
    "# ==========================================\n",
    "# 5. Enhanced Evaluation Functions\n",
    "# ==========================================\n",
    "def evaluate_link_prediction_enhanced(model, data_t0, data_t1, device, \n",
    "                                     sampling_strategy='random',\n",
    "                                     train_history=None, test_history=None,\n",
    "                                     model_name=\"Model\"):\n",
    "    \"\"\"拡張評価関数\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_t0 = data_t0.to(device)\n",
    "        data_t1 = data_t1.to(device)\n",
    "        \n",
    "        if isinstance(model, (InnoVeloODE, GRAND_ODE, GREAD_ODE)):\n",
    "            t_span = torch.tensor([0.0, 1.0]).to(device)\n",
    "            z_traj = model(data_t0.x, data_t0.edge_index, t_span, data_t0.num_nodes)\n",
    "            z_pred = z_traj[-1]\n",
    "        elif isinstance(model, GCN_LSTM):\n",
    "            z_pred = model.encode_snapshot(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "        elif isinstance(model, SimpleMemoryGNN):\n",
    "            z_pred = model.encode(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "        else:\n",
    "            z_pred = model.encode(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "        \n",
    "        pos_edge = data_t1.edge_index\n",
    "        \n",
    "        if sampling_strategy == 'random':\n",
    "            neg_edge = NegativeSampler.random_negative_sampling(\n",
    "                pos_edge, data_t1.num_nodes, pos_edge.size(1)\n",
    "            )\n",
    "        elif sampling_strategy == 'historical' and train_history is not None:\n",
    "            neg_edge = NegativeSampler.historical_negative_sampling(\n",
    "                train_history, pos_edge, data_t1.num_nodes, pos_edge.size(1)\n",
    "            )\n",
    "        elif sampling_strategy == 'inductive' and test_history is not None:\n",
    "            neg_edge = NegativeSampler.inductive_negative_sampling(\n",
    "                test_history, pos_edge, data_t1.num_nodes, pos_edge.size(1)\n",
    "            )\n",
    "        else:\n",
    "            neg_edge = NegativeSampler.random_negative_sampling(\n",
    "                pos_edge, data_t1.num_nodes, pos_edge.size(1)\n",
    "            )\n",
    "        \n",
    "        pos_score = model.predict_link(z_pred, pos_edge)\n",
    "        neg_score = model.predict_link(z_pred, neg_edge)\n",
    "        \n",
    "        y_true = torch.cat([\n",
    "            torch.ones_like(pos_score),\n",
    "            torch.zeros_like(neg_score)\n",
    "        ]).cpu().numpy()\n",
    "        y_pred = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "        \n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        ap = average_precision_score(y_true, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'AUC': auc,\n",
    "            'AP': ap,\n",
    "            'pos_score_mean': pos_score.mean().item(),\n",
    "            'neg_score_mean': neg_score.mean().item()\n",
    "        }\n",
    "\n",
    "def evaluate_multi_step_enhanced(model, snapshots, years, device, \n",
    "                                sampling_strategy='random', model_name=\"Model\"):\n",
    "    results = []\n",
    "    \n",
    "    train_history = []\n",
    "    test_history = []\n",
    "    \n",
    "    for i in range(len(years) - 2):\n",
    "        t0, t1, t2 = years[i], years[i+1], years[i+2]\n",
    "        \n",
    "        if i > 0:\n",
    "            train_history.append(snapshots[years[i-1]].edge_index)\n",
    "            test_history.append(snapshots[t1].edge_index)\n",
    "        \n",
    "        metrics_1step = evaluate_link_prediction_enhanced(\n",
    "            model, snapshots[t0], snapshots[t1], device,\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            train_history=train_history if len(train_history) > 0 else None,\n",
    "            test_history=test_history if len(test_history) > 0 else None,\n",
    "            model_name=model_name\n",
    "        )\n",
    "        \n",
    "        metrics_2step = evaluate_link_prediction_enhanced(\n",
    "            model, snapshots[t0], snapshots[t2], device,\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            train_history=train_history if len(train_history) > 0 else None,\n",
    "            test_history=test_history if len(test_history) > 0 else None,\n",
    "            model_name=model_name\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'sampling': sampling_strategy,\n",
    "            'time_window': f\"{t0}->{t1}->{t2}\",\n",
    "            '1_step_AUC': metrics_1step['AUC'],\n",
    "            '1_step_AP': metrics_1step['AP'],\n",
    "            '2_step_AUC': metrics_2step['AUC'],\n",
    "            '2_step_AP': metrics_2step['AP']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 詳細評価用ユーティリティ (パラメータ数, 時間, MRR, トレンド相関)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# --- ユーティリティ: モデル統計 (パラメータ数 & 推論時間) ---\n",
    "class ModelStats:\n",
    "    @staticmethod\n",
    "    def count_parameters(model):\n",
    "        \"\"\"学習可能なパラメータ数をカウント\"\"\"\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    @staticmethod\n",
    "    def measure_inference_time(model, data, device, runs=10):\n",
    "        \"\"\"推論時間(ミリ秒)を計測\"\"\"\n",
    "        model.eval()\n",
    "        data = data.to(device)\n",
    "        t_span = torch.tensor([0.0, 1.0]).to(device)\n",
    "        \n",
    "        # ウォームアップ\n",
    "        with torch.no_grad():\n",
    "            _ = model_forward_wrapper(model, data, t_span)\n",
    "            \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            for _ in range(runs):\n",
    "                _ = model_forward_wrapper(model, data, t_span)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        avg_time_ms = ((end_time - start_time) / runs) * 1000\n",
    "        return avg_time_ms\n",
    "\n",
    "def model_forward_wrapper(model, data, t_span):\n",
    "    \"\"\"モデルごとのforwardの違いを吸収するラッパー\"\"\"\n",
    "    if isinstance(model, (InnoVeloODE, GRAND_ODE, GREAD_ODE)):\n",
    "        return model(data.x, data.edge_index, t_span, data.num_nodes)[-1]\n",
    "    elif hasattr(model, 'encode_snapshot'): # GCN_LSTM\n",
    "        return model.encode_snapshot(data.x, data.edge_index, data.num_nodes)\n",
    "    else: # Static models\n",
    "        return model.encode(data.x, data.edge_index, data.num_nodes)\n",
    "\n",
    "# --- 評価指標: MRR, Hits@K ---\n",
    "def compute_ranking_metrics(pos_scores, neg_scores_matrix):\n",
    "    \"\"\"\n",
    "    pos_scores: [Num_Edges]\n",
    "    neg_scores_matrix: [Num_Edges, Num_Negatives]\n",
    "    \"\"\"\n",
    "    # 正解スコアを [N, 1] に変形して結合 -> [N, K+1]\n",
    "    all_scores = torch.cat([pos_scores.unsqueeze(1), neg_scores_matrix], dim=1)\n",
    "    \n",
    "    # 降順ソート (大きい値が上位)\n",
    "    _, sorted_indices = torch.sort(all_scores, dim=1, descending=True)\n",
    "    \n",
    "    # インデックス0（正解）が何番目にあるか (Rankは1始まり)\n",
    "    hits_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1\n",
    "    hits_rank = hits_rank.float()\n",
    "    \n",
    "    mrr = (1.0 / hits_rank).mean().item()\n",
    "    hits10 = (hits_rank <= 10).float().mean().item()\n",
    "    hits50 = (hits_rank <= 50).float().mean().item()\n",
    "    \n",
    "    return mrr, hits10, hits50\n",
    "\n",
    "# --- 評価指標: トレンド相関 ---\n",
    "def compute_trend_correlation(model, data_t0, data_t1, z_t0_pred, device):\n",
    "    \"\"\"予測された「勢い」と、実際の「引用増加数」の相関を計算\"\"\"\n",
    "    # 1. Ground Truth: 次のステップでの引用増加数\n",
    "    deg_t0 = data_t0.edge_index[1].bincount(minlength=data_t0.num_nodes).float()\n",
    "    deg_t1 = data_t1.edge_index[1].bincount(minlength=data_t1.num_nodes).float()\n",
    "    future_citation_growth = (deg_t1 - deg_t0).cpu().numpy()\n",
    "    \n",
    "    # 2. Predicted Momentum\n",
    "    if isinstance(model, InnoVeloODE):\n",
    "        model.ode_func.set_component_storage(True)\n",
    "        with torch.no_grad():\n",
    "             t0 = torch.tensor(0.0).to(device)\n",
    "             z0_aug = model.encode(data_t0.x.to(device), data_t0.num_nodes)\n",
    "             derivatives = model.ode_func(t0, z0_aug) \n",
    "             # dh/dt = velocity\n",
    "             velocity_vec = derivatives[:, :model.hidden_dim]\n",
    "             predicted_momentum = torch.norm(velocity_vec, dim=1).cpu().numpy()\n",
    "        model.ode_func.set_component_storage(False)\n",
    "    else:\n",
    "        # 静的モデル等は特徴量ノルムで代用（比較用）\n",
    "        predicted_momentum = torch.norm(z_t0_pred, dim=1).cpu().numpy()\n",
    "\n",
    "    # 3. 相関係数の計算 (引用増加があるノードに限定するとより鮮明)\n",
    "    mask = future_citation_growth > 0\n",
    "    if mask.sum() > 100:\n",
    "        corr, _ = spearmanr(predicted_momentum[mask], future_citation_growth[mask])\n",
    "    else:\n",
    "        corr, _ = spearmanr(predicted_momentum, future_citation_growth)\n",
    "        \n",
    "    return corr\n",
    "\n",
    "def evaluate_comprehensive(model, data_t0, data_t1, device, model_name=\"Model\"):\n",
    "    \"\"\"包括的評価の実行関数\"\"\"\n",
    "    model.eval()\n",
    "    data_t0 = data_t0.to(device)\n",
    "    data_t1 = data_t1.to(device)\n",
    "    \n",
    "    # 1. 埋め込み計算 & 時間計測\n",
    "    t_span = torch.tensor([0.0, 1.0]).to(device)\n",
    "    inference_time = ModelStats.measure_inference_time(model, data_t0, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z_pred = model_forward_wrapper(model, data_t0, t_span)\n",
    "\n",
    "    # 2. リンク予測 (AUC / AP)\n",
    "    pos_edge = data_t1.edge_index\n",
    "    neg_edge = NegativeSampler.random_negative_sampling(pos_edge, data_t1.num_nodes, pos_edge.size(1))\n",
    "    \n",
    "    pos_score = model.predict_link(z_pred, pos_edge)\n",
    "    neg_score = model.predict_link(z_pred, neg_edge)\n",
    "    \n",
    "    y_true = torch.cat([torch.ones_like(pos_score), torch.zeros_like(neg_score)]).cpu().numpy()\n",
    "    y_pred = torch.cat([pos_score, neg_score]).detach().cpu().numpy()\n",
    "    \n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    # 3. ランキング評価 (MRR, Hits@K) - サンプリング評価\n",
    "    num_eval_samples = 1000 # 評価高速化のため1000エッジのみ使用\n",
    "    if pos_edge.size(1) > num_eval_samples:\n",
    "        indices = torch.randperm(pos_edge.size(1))[:num_eval_samples]\n",
    "        sample_pos_edges = pos_edge[:, indices]\n",
    "    else:\n",
    "        sample_pos_edges = pos_edge\n",
    "        \n",
    "    num_neg_candidates = 50\n",
    "    batch_neg_edges = negative_sampling(sample_pos_edges, num_nodes=data_t1.num_nodes, \n",
    "                                      num_neg_samples=sample_pos_edges.size(1) * num_neg_candidates)\n",
    "    \n",
    "    sample_pos_scores = model.predict_link(z_pred, sample_pos_edges)\n",
    "    batch_neg_scores = model.predict_link(z_pred, batch_neg_edges)\n",
    "    batch_neg_scores_matrix = batch_neg_scores.view(sample_pos_edges.size(1), num_neg_candidates)\n",
    "    \n",
    "    mrr, hits10, hits50 = compute_ranking_metrics(sample_pos_scores, batch_neg_scores_matrix)\n",
    "\n",
    "    # 4. トレンド相関\n",
    "    trend_corr = compute_trend_correlation(model, data_t0, data_t1, z_pred, device)\n",
    "\n",
    "    # 5. パラメータ数\n",
    "    params = ModelStats.count_parameters(model)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'Params': params,\n",
    "        'Time(ms)': round(inference_time, 2),\n",
    "        'AUC': auc,\n",
    "        'AP': ap,\n",
    "        'MRR': mrr,\n",
    "        'Hits@10': hits10,\n",
    "        'Hits@50': hits50,\n",
    "        'Trend_Corr': trend_corr\n",
    "    }\n",
    "\n",
    "# ==========================================\n",
    "# 6. Training Function\n",
    "# ==========================================\n",
    "def train_model(model, snapshots, years, device, epochs=5, lr=0.01, model_name=\"Model\"):\n",
    "    \"\"\"モデルの学習\"\"\"\n",
    "    \n",
    "    if isinstance(model, SimpleMemoryGNN):\n",
    "        model.init_memory(snapshots[years[0]].num_nodes, device)\n",
    "    \n",
    "    # EdgeBankの訓練をスキップ\n",
    "    if not isinstance(model, (StaticGCN, GCN_LSTM, GraphSAGEModel, SimpleMemoryGNN, InnoVeloODE, GRAND_ODE, GREAD_ODE)):\n",
    "        print(f\"Skipping training for non-parametric model: {model_name}.\")\n",
    "        return []\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_years = years[-4:] if len(years) >= 4 else years\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_auc = 0\n",
    "        steps = 0\n",
    "        \n",
    "        for i in range(len(train_years) - 1):\n",
    "            t0, t1 = train_years[i], train_years[i+1]\n",
    "            data_t0 = snapshots[t0].to(device)\n",
    "            data_t1 = snapshots[t1].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass\n",
    "            if isinstance(model, (InnoVeloODE, GRAND_ODE, GREAD_ODE)):\n",
    "                t_span = torch.tensor([0.0, 1.0]).to(device)\n",
    "                z_traj = model(data_t0.x, data_t0.edge_index, t_span, data_t0.num_nodes)\n",
    "                z_t1_pred = z_traj[-1]\n",
    "            elif isinstance(model, GCN_LSTM):\n",
    "                z_t1_pred = model.encode_snapshot(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "            else:\n",
    "                z_t1_pred = model.encode(data_t0.x, data_t0.edge_index, data_t0.num_nodes)\n",
    "            \n",
    "            pos_edge_index = data_t1.edge_index\n",
    "            neg_edge_index = negative_sampling(\n",
    "                pos_edge_index, num_nodes=data_t1.num_nodes,\n",
    "                num_neg_samples=pos_edge_index.size(1)\n",
    "            )\n",
    "            \n",
    "            pos_score = model.predict_link(z_t1_pred, pos_edge_index)\n",
    "            neg_score = model.predict_link(z_t1_pred, neg_edge_index)\n",
    "            \n",
    "            loss = -torch.log(pos_score + 1e-15).mean() - torch.log(1 - neg_score + 1e-15).mean()\n",
    "            \n",
    "            # 運動エネルギー正則化 (InnoVeloODEのみ) - インデントと位置を修正\n",
    "            if isinstance(model, InnoVeloODE) and model.ode_func.ablation_mode != 'no_velocity':\n",
    "                # z_trajは上のifブロックで定義されている\n",
    "                z_final = z_traj[-1]\n",
    "                v_final = z_final[:, model.hidden_dim:] \n",
    "                kinetic_energy = torch.mean(v_final ** 2)\n",
    "                loss += 1.0 * kinetic_energy\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            steps += 1\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                y_true = torch.cat([\n",
    "                    torch.ones_like(pos_score),\n",
    "                    torch.zeros_like(neg_score)\n",
    "                ]).cpu().numpy()\n",
    "                y_pred = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "                total_auc += roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "        avg_loss = total_loss / steps if steps > 0 else 0\n",
    "        avg_auc = total_auc / steps if steps > 0 else 0\n",
    "        \n",
    "        history.append({'epoch': epoch+1, 'loss': avg_loss, 'auc': avg_auc})\n",
    "        print(f\"{model_name} - Epoch {epoch+1:02d}/{epochs} | Loss: {avg_loss:.4f} | AUC: {avg_auc:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# ==========================================\n",
    "# 7. Streamline Visualizer (瞬時速度場)\n",
    "# ==========================================\n",
    "class StreamlineVisualizer:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.category_names = ARXIV_CATEGORY_NAMES \n",
    "\n",
    "    def _get_embeddings_and_components(self, snapshot):\n",
    "        data = snapshot.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.model, InnoVeloODE):\n",
    "                z0 = self.model.encode(data.x, data.num_nodes)\n",
    "                \n",
    "                # 瞬時速度場（dz/dt）を取得\n",
    "                self.model.ode_func.set_component_storage(True)\n",
    "                dz_dt_t0 = self.model.ode_func(torch.tensor(0.0).to(z0.device), z0)\n",
    "                self.model.ode_func.set_component_storage(False)\n",
    "                \n",
    "                z_start = z0.cpu().numpy()\n",
    "                labels = data.y.cpu().numpy().flatten()\n",
    "                \n",
    "                components_tensor = self.model.ode_func.get_components()\n",
    "                components = {k: v.cpu().numpy() for k, v in components_tensor.items()}\n",
    "                \n",
    "                velocities_t0 = dz_dt_t0.cpu().numpy()\n",
    "            \n",
    "            else:\n",
    "                # ODEモデル以外の場合、ダミー速度場を生成\n",
    "                z_start = self.model.encode(data.x, data.edge_index, data.num_nodes).cpu().numpy()\n",
    "                velocities_t0 = np.random.randn(*z_start.shape) * 0.1 \n",
    "                labels = data.y.cpu().numpy().flatten()\n",
    "                components = {\n",
    "                    'dz_dt': velocities_t0,\n",
    "                    'velocity': velocities_t0 * 0.5,\n",
    "                    'diffusion': velocities_t0 * 0.3,\n",
    "                    'decay': velocities_t0 * 0.2\n",
    "                }\n",
    "            \n",
    "            num_cats = self.model.num_cats\n",
    "            # カテゴリノードのみを抽出\n",
    "            valid_mask = (labels >= 0) & (labels < num_cats) \n",
    "        \n",
    "        z_start = z_start[valid_mask]\n",
    "        labels = labels[valid_mask]\n",
    "        velocities_t0 = velocities_t0[valid_mask]\n",
    "        for k in components:\n",
    "            components[k] = components[k][valid_mask]\n",
    "\n",
    "        if z_start.shape[0] == 0:\n",
    "            return None, None, None, None\n",
    "        \n",
    "        # ノードのサンプリングを導入（最大3000ノード）みやすくするため\n",
    "        num_points = z_start.shape[0]\n",
    "        max_points = 3000  # 最大プロット数を設定\n",
    "        if num_points > max_points:\n",
    "            print(f\"Sampling {max_points} out of {num_points} nodes for visualization...\")\n",
    "            idx = np.random.choice(num_points, max_points, replace=False)\n",
    "            \n",
    "            z_start = z_start[idx]\n",
    "            labels = labels[idx]\n",
    "            velocities_t0 = velocities_t0[idx]\n",
    "            for k in components:\n",
    "                components[k] = components[k][idx]\n",
    "\n",
    "        # UMAPで2次元に圧縮 (n_neighborsを調整)\n",
    "        reducer = umap.UMAP(n_components=2, n_neighbors=min(5, z_start.shape[0]-1), min_dist=0.1, random_state=42)\n",
    "        emb_start = reducer.fit_transform(z_start)\n",
    "        \n",
    "        # 瞬時速度ベクトルをUMAP空間で近似\n",
    "        epsilon = 0.1 \n",
    "        emb_end_approx = reducer.transform(z_start + epsilon * velocities_t0)\n",
    "        velocities_umap = (emb_end_approx - emb_start) / epsilon\n",
    "        \n",
    "        return emb_start, labels, components, velocities_umap\n",
    "\n",
    "    def plot_streamline(self, snapshot, title=\"Tech Trend Streamline\", save_prefix=\"streamline\"):\n",
    "        emb_start, labels, components, velocities_umap = self._get_embeddings_and_components(snapshot)\n",
    "        if emb_start is None:\n",
    "            print(\"No valid data for streamline visualization\")\n",
    "            return\n",
    "\n",
    "        x, y = emb_start[:, 0], emb_start[:, 1]\n",
    "        u, v = velocities_umap[:, 0], velocities_umap[:, 1] \n",
    "        \n",
    "        # Net Velocity (dz/dt) の大きさを計算\n",
    "        net_velocity_magnitude = np.linalg.norm(components['dz_dt'], axis=1)\n",
    "        \n",
    "        min_size = 5\n",
    "        max_size_range = 195\n",
    "\n",
    "        # 1. ノードサイズの動的スケーリング: 速度の大きさに応じてサイズを100から500の範囲でスケーリング\n",
    "        if net_velocity_magnitude.max() > 0:\n",
    "            scaled_size = min_size + max_size_range * (net_velocity_magnitude / net_velocity_magnitude.max())\n",
    "        else:\n",
    "            scaled_size = np.full_like(net_velocity_magnitude, 200)\n",
    "\n",
    "        grid_dim = 50\n",
    "        xi = np.linspace(x.min(), x.max(), grid_dim)\n",
    "        yi = np.linspace(y.min(), y.max(), grid_dim)\n",
    "        \n",
    "        ui = griddata((x, y), u, (xi[None, :], yi[:, None]), method='linear')\n",
    "        vi = griddata((x, y), v, (xi[None, :], yi[:, None]), method='linear')\n",
    "        ui = np.nan_to_num(ui); vi = np.nan_to_num(vi)\n",
    "        \n",
    "        speed_grid = np.sqrt(ui**2 + vi**2)\n",
    "        lw = 3.0 * speed_grid / speed_grid.max() if speed_grid.max() > 0 else 1.0\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 20))\n",
    "        unique_labels = np.unique(labels)\n",
    "        \n",
    "        colors = plt.colormaps.get_cmap('tab20c')\n",
    "        \n",
    "        # 修正されたノードサイズを使用\n",
    "        ax.scatter(x, y, c=labels, cmap=colors, s=scaled_size, alpha=0.4, edgecolors='k', linewidths=0.5)\n",
    "        ax.streamplot(xi, yi, ui, vi, color='black', linewidth=lw, arrowsize=1.5, density=1.0, cmap='plasma')\n",
    "        \n",
    "        # 2. ラベルの強調\n",
    "        for label in unique_labels:\n",
    "            mask = (labels == label)\n",
    "            if np.sum(mask) > 0:\n",
    "                cx = np.mean(x[mask]); cy = np.mean(y[mask])\n",
    "                cat_id_str = str(int(label))\n",
    "                ax.text(cx, cy, cat_id_str, fontsize=12, fontweight='bold', \n",
    "                        bbox=dict(boxstyle=\"round,pad=0.5\", fc='white', alpha=0.9, \n",
    "                                  ec=colors(label), linewidth=2)) # 外枠を強調\n",
    "\n",
    "        # 保存パスにディレクトリを付加\n",
    "        final_save_path = os.path.join(OUTPUT_DIR, save_prefix)\n",
    "\n",
    "        # Raw f-stringによるLaTeXタイトルの表示 (最終修正版)\n",
    "        ax.set_title(rf\"{title} (Instantaneous Velocity Field: $\\frac{{dz}}{{dt}}|_{{t=0}}$)\", fontsize=18, pad=20)\n",
    "        ax.set_xlabel(\"UMAP Dimension 1\")\n",
    "        ax.set_ylabel(\"UMAP Dimension 2\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{final_save_path}.png\", dpi=300); plt.savefig(f\"{final_save_path}.pdf\", bbox_inches='tight')\n",
    "        print(f\"Saved: {final_save_path}.png and {final_save_path}.pdf\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    def plot_velocity_components(self, snapshot, title_suffix=\"Velocity Components\", \n",
    "                                 save_prefix=\"velocity_components\"):\n",
    "        emb_start, labels, components, _ = self._get_embeddings_and_components(snapshot)\n",
    "        if emb_start is None:\n",
    "            print(\"No valid data for velocity components visualization\")\n",
    "            return\n",
    "\n",
    "        x, y = emb_start[:, 0], emb_start[:, 1]\n",
    "        \n",
    "        plot_data = {\n",
    "            'Net Velocity (dz/dt)': np.linalg.norm(components['dz_dt'], axis=1),\n",
    "            'Diffusion (GNN)': np.linalg.norm(components['diffusion'], axis=1),\n",
    "            'Intrinsic Velocity': np.linalg.norm(components['velocity'], axis=1),\n",
    "        }\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "        min_size = 5\n",
    "        max_size_range = 195\n",
    "        \n",
    "        for ax, (comp_name, comp_magnitude) in zip(axes, plot_data.items()):\n",
    "            if comp_magnitude.max() > 0:\n",
    "                norm_magnitude = comp_magnitude / comp_magnitude.max()\n",
    "            else:\n",
    "                norm_magnitude = comp_magnitude\n",
    "            \n",
    "            # ここでもノードサイズを動的に変更\n",
    "            scaled_size = min_size + max_size_range * (norm_magnitude)\n",
    "            \n",
    "            scatter = ax.scatter(x, y, c=comp_magnitude, cmap='viridis',\n",
    "                               s=scaled_size, alpha=0.5,\n",
    "                               edgecolors='k', linewidths=0.5)\n",
    "            \n",
    "            fig.colorbar(scatter, ax=ax, label='Magnitude (Strength)')\n",
    "            ax.set_title(comp_name)\n",
    "            ax.set_xlabel(\"UMAP Dimension 1\")\n",
    "            ax.set_ylabel(\"UMAP Dimension 2\")\n",
    "\n",
    "        final_save_path = os.path.join(OUTPUT_DIR, save_prefix)\n",
    "\n",
    "        plt.suptitle(f\"Velocity Field Components Analysis - {title_suffix}\", fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f\"{final_save_path}.png\", dpi=300); plt.savefig(f\"{final_save_path}.pdf\", bbox_inches='tight')\n",
    "        print(f\"Saved: {final_save_path}.png and {final_save_path}.pdf\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    def plot_vector_field_grid(self, snapshot, title=\"Velocity Field (Grid)\", \n",
    "                               save_prefix=\"vector_field_grid\", grid_density=20):\n",
    "        \"\"\"\n",
    "        速度場をグリッド状の矢印で可視化（より整然とした表示）\n",
    "        \"\"\"\n",
    "        emb_start, labels, componets, velocities_umap = self._get_embeddings_and_components(snapshot)\n",
    "        if emb_start is None:\n",
    "            print(\"No valid data for vector field grid visualization\")\n",
    "            return\n",
    "        \n",
    "        x, y = emb_start[:, 0], emb_start[:, 1]\n",
    "        u, v = velocities_umap[:, 0], velocities_umap[:, 1]\n",
    "\n",
    "        xi = np.linspace(x.min(), x.max(), grid_density)\n",
    "        yi = np.linspace(y.min(), y.max(), grid_density)\n",
    "        XI, YI = np.meshgrid(xi, yi)\n",
    "\n",
    "        from scipy.interpolate import griddata\n",
    "        UI = griddata((x, y), u, (XI, YI), method='linear', fill_value=0)\n",
    "        VI = griddata((x, y), v, (XI, YI), method='linear', fill_value=0)\n",
    "\n",
    "        speed = np.sqrt(UI**2 + VI**2)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "        colors = plt.colormaps.get_cmap('tab20c')\n",
    "        net_velocity_magnitude = np.linalg.norm(componets['dz_dt'], axis=1)\n",
    "        scaled_size = 5 + 195 * (net_velocity_magnitude / net_velocity_magnitude.max()) if net_velocity_magnitude.max() > 0 else np.full_like(net_velocity_magnitude, 100)\n",
    "\n",
    "        ax.scatter(x, y, c=labels, cmap=colors, s=scaled_size, alpha=0.4, edgecolors='k', linewidths=0.5, zorder=1)\n",
    "\n",
    "        quiver = ax.quiver(XI, YI, UI, VI, speed, cmap='plasma', scale=50, width=0.003, zorder=2)\n",
    "\n",
    "        cbar = plt.colorbar(quiver, ax=ax, fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Velocity Magnitude', fontsize=14)\n",
    "\n",
    "        unique_labels = np.unique(labels)\n",
    "        for label in unique_labels:\n",
    "            mask = (labels == label)\n",
    "            if np.sum(mask) > 0:\n",
    "                cx = np.mean(x[mask])\n",
    "                cy = np.mean(y[mask])\n",
    "                cat_id_str = str(int(label))\n",
    "                ax.text(cx, cy, cat_id_str, fontsize=12, fontweight='bold',\n",
    "                       bbox=dict(boxstyle=\"round,pad=0.5\", fc='white', alpha=0.9,\n",
    "                                ec=colors(label), linewidth=2), zorder=3)\n",
    "        \n",
    "        final_save_path = os.path.join(OUTPUT_DIR, save_prefix)\n",
    "        \n",
    "        ax.set_title(rf\"{title} (Grid Interpolation: $\\vec{{v}}(x,y)$)\", \n",
    "                    fontsize=18, pad=20)\n",
    "        ax.set_xlabel(\"UMAP Dimension 1\", fontsize=14)\n",
    "        ax.set_ylabel(\"UMAP Dimension 2\", fontsize=14)\n",
    "        ax.grid(True, alpha=0.2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{final_save_path}.png\", dpi=300)\n",
    "        plt.savefig(f\"{final_save_path}.pdf\", bbox_inches='tight')\n",
    "        print(f\"Saved: {final_save_path}.png and {final_save_path}.pdf\")\n",
    "        plt.close(fig)\n",
    "\n",
    "# ==========================================\n",
    "# 8. Graph Structure Visualizer\n",
    "# ==========================================\n",
    "class GraphStructureVisualizer:\n",
    "    def __init__(self, df_nodes, df_edges):\n",
    "        self.df_nodes = df_nodes\n",
    "        self.df_edges = df_edges\n",
    "        self.category_names = ARXIV_CATEGORY_NAMES \n",
    "        \n",
    "    def plot_category_subgraph(self, category_id, num_papers=100):\n",
    "        cat_name = self.category_names.get(category_id, f'Cat {category_id}')\n",
    "        print(f\"Generating Subgraph Visualization for Category {cat_name}...\")\n",
    "        \n",
    "        category_papers = self.df_nodes[self.df_nodes['category'] == category_id]\n",
    "        if category_papers.empty:\n",
    "            print(f\"Category {category_id} not found.\")\n",
    "            return\n",
    "\n",
    "        category_papers = category_papers.sort_values(by='year', ascending=False).head(num_papers)\n",
    "        paper_ids = set(category_papers['node_id'].values)\n",
    "        sub_edges = self.df_edges[\n",
    "            (self.df_edges['source'].isin(paper_ids)) & \n",
    "            (self.df_edges['target'].isin(paper_ids))\n",
    "        ]\n",
    "\n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(sub_edges[['source', 'target']].values)\n",
    "        \n",
    "        if not G.nodes:\n",
    "            print(f\"No citation links found within the top {num_papers} papers of Category {category_id}.\")\n",
    "            return\n",
    "            \n",
    "        node_years = category_papers.set_index('node_id')['year'].to_dict()\n",
    "        nx.set_node_attributes(G, node_years, 'year')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 20))\n",
    "        pos = nx.spring_layout(G, k=0.15, iterations=50, seed=42)\n",
    "        years_list = [G.nodes[n]['year'] for n in G.nodes if 'year' in G.nodes[n]]\n",
    "        \n",
    "        if not years_list:\n",
    "             cmap = plt.cm.get_cmap('YlOrRd')\n",
    "             norm = plt.Normalize(vmin=0, vmax=1)\n",
    "        else:\n",
    "             cmap = plt.cm.get_cmap('YlOrRd')\n",
    "             norm = plt.Normalize(vmin=min(years_list), vmax=max(years_list))\n",
    "             node_colors = years_list\n",
    "        \n",
    "        nx.draw_networkx_nodes(G, pos, node_size=150, node_color=years_list, \n",
    "                              cmap=cmap, edgecolors='gray', linewidths=0.5, ax=ax)\n",
    "        nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=10, \n",
    "                              edge_color='gray', alpha=0.6, ax=ax)\n",
    "        node_labels = {node: str(node) for node in G.nodes()}\n",
    "        nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=8, font_color='black', ax=ax)\n",
    "        \n",
    "        if years_list:\n",
    "            sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "            sm.set_array(years_list)\n",
    "            plt.colorbar(sm, ax=ax, orientation='vertical', label='Publication Year')\n",
    "\n",
    "        ax.set_title(f\"Citation Subgraph: {cat_name} (Top {num_papers} Papers)\", \n",
    "                    fontsize=20)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        final_file_prefix = os.path.join(OUTPUT_DIR, f\"subgraph_cat_{category_id}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{final_file_prefix}.png\", dpi=300)\n",
    "        plt.savefig(f\"{final_file_prefix}.pdf\", bbox_inches='tight')\n",
    "        print(f\"Saved: {final_file_prefix}.png and {final_file_prefix}.pdf\")\n",
    "        plt.close(fig)\n",
    "\n",
    "# ==========================================\n",
    "# 9. Results Comparison & Visualization\n",
    "# ==========================================\n",
    "def plot_sampling_comparison(all_results, save_prefix=\"sampling_comparison\"):\n",
    "    \"\"\"複数のサンプリング戦略での比較可視化\"\"\"\n",
    "    sampling_strategies = all_results['sampling'].unique()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "    metrics = ['1_step_AUC', '1_step_AP', '2_step_AUC', '2_step_AP']\n",
    "    titles = ['1-Step AUC', '1-Step AP', '2-Step AUC', '2-Step AP']\n",
    "    \n",
    "    for ax, metric, title in zip(axes.flat, metrics, titles):\n",
    "        for strategy in sampling_strategies:\n",
    "            strategy_data = all_results[all_results['sampling'] == strategy]\n",
    "            for model_name in strategy_data['model'].unique():\n",
    "                model_data = strategy_data[strategy_data['model'] == model_name]\n",
    "                label = f\"{model_name} ({strategy})\"\n",
    "                linestyle = '-' if strategy == 'random' else '--' if strategy == 'historical' else ':'\n",
    "                ax.plot(range(len(model_data)), model_data[metric], \n",
    "                       marker='o', label=label, linewidth=2, linestyle=linestyle)\n",
    "        \n",
    "        ax.set_xlabel('Time Window Index', fontsize=12)\n",
    "        ax.set_ylabel(title, fontsize=12)\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=8, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim([0, 1])\n",
    "    \n",
    "    plt.suptitle('Performance Comparison Across Sampling Strategies', fontsize=16, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_prefix}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.savefig(f\"{save_prefix}.pdf\", bbox_inches='tight')\n",
    "    print(f\"Saved: {save_prefix}.png and {save_prefix}.pdf\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def print_summary_table(all_results):\n",
    "    \"\"\"結果の要約表を出力\"\"\"\n",
    "    summary = all_results.groupby(['model', 'sampling']).agg({\n",
    "        '1_step_AUC': ['mean', 'std'],\n",
    "        '1_step_AP': ['mean', 'std'],\n",
    "        '2_step_AUC': ['mean', 'std'],\n",
    "        '2_step_AP': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"MODEL COMPARISON SUMMARY (BY SAMPLING STRATEGY)\")\n",
    "    print(\"=\"*100)\n",
    "    print(summary)\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# ==========================================\n",
    "# 10. Main Execution Pipeline\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"DYNAMIC GRAPH LEARNING WITH ADVANCED EVALUATION\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    # ハイパーパラメータ\n",
    "    HIDDEN_DIM = 32\n",
    "    EPOCHS = 5\n",
    "    LR = 0.01\n",
    "    USE_GAT = True\n",
    "    GAT_HEADS = 2   \n",
    "    \n",
    "    # 評価するサンプリング戦略\n",
    "    SAMPLING_STRATEGIES = ['random', 'historical', 'inductive']\n",
    "    \n",
    "    # 1. データロード\n",
    "    print(\"STEP 1: Loading Data...\")\n",
    "    factory = UniversalDataFactory('ogbn-arxiv')\n",
    "    raw_data = factory.load_data()\n",
    "    \n",
    "    # 2. グラフ構築\n",
    "    print(\"\\nSTEP 2: Building Dynamic Graphs...\")\n",
    "    builder = DynamicGraphBuilder(raw_data)\n",
    "    snapshots, num_cats, feat_dim = builder.build_snapshots()\n",
    "    years = sorted(snapshots.keys())\n",
    "    \n",
    "    if len(years) < 2:\n",
    "        print(\"Error: Not enough time steps for training.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✓ Time snapshots: {years}\")\n",
    "    print(f\"✓ Categories: {num_cats}, Feature dim: {feat_dim}\")\n",
    "    \n",
    "    # 3. モデル初期化\n",
    "    print(\"\\nSTEP 3: Initializing Models (Baselines & Ablation)...\")\n",
    "    models = {\n",
    "        'Static GCN': StaticGCN(num_cats, feat_dim, HIDDEN_DIM).to(device),\n",
    "        'GRAND (Diffusion)': GRAND_ODE(num_cats, feat_dim, HIDDEN_DIM).to(device),\n",
    "        'GREAD (React-Diff)': GREAD_ODE(num_cats, feat_dim, HIDDEN_DIM).to(device),\n",
    "        \n",
    "        # --- InnoVeloODE Ablation Studies ---\n",
    "        'InnoVelo (Full)': InnoVeloODE(\n",
    "            num_cats, feat_dim, HIDDEN_DIM, use_gat=USE_GAT, gat_heads=GAT_HEADS,\n",
    "            ablation_mode='adaptive_decay'\n",
    "        ).to(device),\n",
    "        \n",
    "        'InnoVelo (No Decay)': InnoVeloODE(\n",
    "            num_cats, feat_dim, HIDDEN_DIM, use_gat=USE_GAT, gat_heads=GAT_HEADS,\n",
    "            ablation_mode='no_decay'\n",
    "        ).to(device),\n",
    "        \n",
    "        'InnoVelo (No Velocity)': InnoVeloODE(\n",
    "            num_cats, feat_dim, HIDDEN_DIM, use_gat=USE_GAT, gat_heads=GAT_HEADS,\n",
    "            ablation_mode='no_velocity'\n",
    "        ).to(device)\n",
    "    }\n",
    "    \n",
    "    for name in models.keys():\n",
    "        print(f\"  ✓ {name}\")\n",
    "    \n",
    "    # 4. 学習\n",
    "    print(\"\\nSTEP 4: Training Models...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        train_model(model, snapshots, years, device, \n",
    "                             epochs=EPOCHS, lr=LR, model_name=name)\n",
    "    \n",
    "    # 5. 複数のサンプリング戦略での評価\n",
    "    print(\"\\nSTEP 5: Evaluating Models with Multiple Sampling Strategies...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    all_results = []\n",
    "    for strategy in SAMPLING_STRATEGIES:\n",
    "        print(f\"\\n### Evaluating with {strategy.upper()} sampling ###\")\n",
    "        for name, model in models.items():\n",
    "            print(f\"  Evaluating {name}...\")\n",
    "            results = evaluate_multi_step_enhanced(\n",
    "                model, snapshots, years, device, \n",
    "                sampling_strategy=strategy, model_name=name\n",
    "            )\n",
    "            all_results.append(results)\n",
    "    \n",
    "    all_results_df = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # 6. 結果の可視化と要約\n",
    "    print(\"\\nSTEP 6: Visualizing Results and Summarizing...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    plot_sampling_comparison(all_results_df, \"sampling_strategy_comparison\")\n",
    "    summary = print_summary_table(all_results_df)\n",
    "    \n",
    "    all_results_df.to_csv(\"evaluation_results_enhanced.csv\", index=False)\n",
    "    summary.to_csv(\"summary_results_enhanced.csv\")\n",
    "    print(\"✓ Saved: evaluation_results_enhanced.csv, summary_results_enhanced.csv\")\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    # STEP 5.5: 包括的ベンチマーク (最後の期間で詳細評価)\n",
    "    # ----------------------------------------------------------------------\n",
    "    print(\"\\nSTEP 5.5: Comprehensive Benchmark (Efficiency, Rank, Trend)...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    final_benchmark_results = []\n",
    "    \n",
    "    # 最後のタイムステップ (例: 2019->2020) で評価を行う\n",
    "    target_year_idx = -2 \n",
    "    t0, t1 = years[target_year_idx], years[target_year_idx+1]\n",
    "    print(f\"Benchmarking on transition: {t0} -> {t1}\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"  Benchmarking {name}...\")\n",
    "        metrics = evaluate_comprehensive(\n",
    "            model, snapshots[t0], snapshots[t1], device, model_name=name\n",
    "        )\n",
    "        final_benchmark_results.append(metrics)\n",
    "    \n",
    "    # 結果を表示\n",
    "    df_bench = pd.DataFrame(final_benchmark_results)\n",
    "    \n",
    "    # 表示する列の順序を整理\n",
    "    cols = ['model', 'Params', 'Time(ms)', 'AUC', 'MRR', 'Hits@10', 'Trend_Corr']\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"FINAL BENCHMARK RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    print(df_bench[cols])\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    df_bench.to_csv(\"final_comprehensive_benchmark.csv\", index=False)\n",
    "\n",
    "    # 7. Neural ODE (GAT版) の詳細可視化\n",
    "    print(\"\\nSTEP 7: Detailed Visualization for InnoVelo (Full)...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    ode_gat_model = models['InnoVelo (Full)']\n",
    "    latest_snapshot = snapshots[years[-1]]\n",
    "\n",
    "    print(\"\\n[A] Identifying Top 3 Models by 2-Step AUC...\")\n",
    "    top_models_names = (all_results_df\n",
    "        .groupby('model')['2_step_AUC']\n",
    "        .mean()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(3)\n",
    "        .index.tolist())\n",
    "\n",
    "    print(f\"Top 3 Models: {top_models_names}\")\n",
    "\n",
    "    print(\"\\n[B] Generating Streamline Visualizations for Top Models...\")\n",
    "    for rank, model_name in enumerate(top_models_names, 1):\n",
    "        if model_name in models:\n",
    "            print(f\"\\n  [{rank}/3] Visualizing {model_name}...\")\n",
    "            visualizer = StreamlineVisualizer(models[model_name], device)\n",
    "\n",
    "            # ファイル名を安全にする\n",
    "            safe_name = model_name.replace(' ', '_').replace('(', '').replace(')', '').lower()\n",
    "\n",
    "            # グリッド補間された速度場\n",
    "            visualizer.plot_vector_field_grid(\n",
    "                latest_snapshot,\n",
    "                title=f\"Top-{rank}: {model_name} - Grid Velocity Field\",\n",
    "                save_prefix=f\"top{rank}_{safe_name}_vector_grid\",\n",
    "                grid_density=25\n",
    "            )\n",
    "\n",
    "            # ストリームライン\n",
    "            visualizer.plot_streamline(\n",
    "                latest_snapshot, \n",
    "                title=f\"Top-{rank}: {model_name} Tech Trend Streamline\",\n",
    "                save_prefix=f\"top{rank}_{safe_name}_streamline\"\n",
    "            )\n",
    "\n",
    "            # 速度成分の分解\n",
    "            visualizer.plot_velocity_components(\n",
    "                latest_snapshot,\n",
    "                title_suffix=f\"Top-{rank}: {model_name}\",\n",
    "                save_prefix=f\"top{rank}_{safe_name}_velocity_components\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"  ⚠️  Model '{model_name}' not found in models dict\")\n",
    "    \n",
    "    # 9. グラフ構造の可視化 (Top Category)\n",
    "    print(\"\\nSTEP 8: Graph Structure Visualization (Top Category)...\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    graph_viz = GraphStructureVisualizer(raw_data['df_nodes'], raw_data['df_edges'])\n",
    "\n",
    "    ALL_CATEGORIES = range(40)\n",
    "\n",
    "    for category_id in ALL_CATEGORIES:\n",
    "        graph_viz.plot_category_subgraph(category_id=category_id, num_papers=100)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ALL VISUALIZATIONS COMPLETED!\")\n",
    "    \n",
    "    # 10. 重要な発見の要約\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ALL EXPERIMENTS COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d3d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
